{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the JupyterHub Deployment Docs for ENGR101 2019Q1 This documentation serves as a record of the JupyterHub Deployment for ENGR101 Winter 2019 at Portland Community College. The GitHub repo for the deployment can be found here: https://github.com/ProfessorKazarinoff/jupyterhub-engr101 Click the menu items on the left to view the deployment steps. Or start Here and click the arrows at the bottom of each page. The documentation site for a previous JupyterHub deployment can be found here There is also a series of blog posts that documents my first JupyterHub deployment in Summer 2018. This documentation builds upon the experience from my two previous JupyterHub depoloyments. Main Steps Install PuTTY, generate SSH keys Create server, non-root sudo user Install JupyterHub and Python packages Aquire and link domain name to server Aquire SSL cirt Create Cooke Secret, Proxy Auth Token, and dhparam.pem Install and configure Nginx Configure JupyterHub JupyterHub as system service Google Authentication Create custom login page Pull assignments down from GitHub for each user Extra configuration","title":"Home"},{"location":"#welcome-to-the-jupyterhub-deployment-docs-for-engr101-2019q1","text":"This documentation serves as a record of the JupyterHub Deployment for ENGR101 Winter 2019 at Portland Community College. The GitHub repo for the deployment can be found here: https://github.com/ProfessorKazarinoff/jupyterhub-engr101 Click the menu items on the left to view the deployment steps. Or start Here and click the arrows at the bottom of each page. The documentation site for a previous JupyterHub deployment can be found here There is also a series of blog posts that documents my first JupyterHub deployment in Summer 2018. This documentation builds upon the experience from my two previous JupyterHub depoloyments.","title":"Welcome to the JupyterHub Deployment Docs for ENGR101 2019Q1"},{"location":"#main-steps","text":"Install PuTTY, generate SSH keys Create server, non-root sudo user Install JupyterHub and Python packages Aquire and link domain name to server Aquire SSL cirt Create Cooke Secret, Proxy Auth Token, and dhparam.pem Install and configure Nginx Configure JupyterHub JupyterHub as system service Google Authentication Create custom login page Pull assignments down from GitHub for each user Extra configuration","title":"Main Steps"},{"location":"add_users/","text":"Add Users We have Nginx and JupyterHub running as system services. We can log into JupyterHub as the non-root sudo user peter , the user we created when we first setup the server. In this section, we will add an additional user to the server and see if we can log in as that user. If you have a very small class or small lab, this may be all the users you need to register. Add Users Create a new user Add the new user to the jupyterhub_config.py file Log to JupyterHub in as the new user Summary Next Steps Adding new users to JupyterHub can be accomplished in a couple of different ways. Users can be added manually to the server from the command line, users can be added in JupyterHub with the Admin dashboard, and users can be added automatically when a user authenticates with a service like GitHub or Google. In this section, we are going to add users to the server manually. We will create a new user on the server and then log into JupyterHub as the new user. Open PuTTY and log into the server. Just to make sure, update the system before proceeding. $ sudo apt-get update $ sudo apt-get upgrade Shutdown JupyterHub and Nginx, then restart both of them. Let's make sure our system service functionality works correctly. $ sudo systemctl stop jupyterhub $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # check if active [Ctrl]+[c] to exit $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # check if active [Ctrl]+[c] to exit Point a web browser at our domain and log into JupyterHub as our non-root sudo user peter . Use the password we set for peter on the server. The JupyterHub login screen is shown below: You should see a couple files in the Jupyter notebook file browser. These are the same files that are in the non-root sudo user's ( peter ) home directory. At the Jupyter notebook file browser, choose [New] \u2192 [Python 3] Try writing a bit of Python code and running it. Imports for numpy and matplotlib should work normally. After messing around with a Jupyter notebook and making sure that imports and plots work correctly, shut down your notebook server. This action does not shut down the Digital Ocean server running JupyterHub, it just shuts down the server (running on the Digital Ocean server) that serves Jupyter notebooks for the user you logged in as. Click the [Control Pannel] button in the upper right-hand corner of the Jupyter notebook. This brings you to a web browser screen that shows buttons for [Stop My Server] and [My Server] and [Logout]. Click the [Stop My Server] button. Finally, logout by clicking the [Log Out] button in the upper right. This brings you back to the JupyterHub Sign in screen. The reason we want to log out is that we are going to create a new user and want to login as that user. If you don't log out, JupyterHub may start you as the user peter . Create a new user If you have a small class or a small lab, creating users one at a time at the command line and assigning them passwords might be all you need to do to get JupyterHub working for your small group. Next, we will create a new user on the server and log in as the new user. For a small group, you could repeat this process a couple times, and send out usernames and passwords to people in your group. On the server, create the new user with the adduser command. I called my new user gabby . $ sudo adduser gabby Set a new password and confirm: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully The user details can be skipped by pressing [Enter]. Then [Y] to complete the new user setup. Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] Add the new user to the jupyterhub_config.py file Now we need to add the new user to the jupyterhub_config.py file. So far the only users we have specified in the file is peter . Open up the jupyterhub_config.py file and edit the lines shown below. $ nano /etc/jupyterhub/jupyterhub_config.py Add the user 'gabby' to c.Authenticator.whitelist = { } # /etc/jupyterhub/jupyterhub_config.py ... # Users c.Authenticator.whitelist = {'peter','gabby'} c.Authenticator.admin_users = {'peter'} ... Save and close the file with [Ctrl]+[x] and [y]. Now restart Jupyterhub to make the changes take effect. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Log to JupyterHub in as the new user Now browse to the domain name we set up before and log into JupyterHub as the new user gabby . Note the new user gabby doesn't have any files in their Jupyter notebook file browser. This is because the home directory of the user gabby is empty. If you create a new notebook, that notebook will be saved in the gabby home directory. Make sure to stop the server and logout as we did before by clicking [Control Panel] in the upper right and selecting [Stop My Server] and [Logout]. Summary In this section, we tested our JupyterHub deployment and added a new user to the server. After the new user was created, we added the new user to the jupyterhub_config.py file. Then we restarted JupyterHub and logged in as our new user. Next Steps The next step is to add Google authentication. This will allow students to log into our JupyterHub server with Google usernames and passwords.","title":"Add Users"},{"location":"add_users/#add-users","text":"We have Nginx and JupyterHub running as system services. We can log into JupyterHub as the non-root sudo user peter , the user we created when we first setup the server. In this section, we will add an additional user to the server and see if we can log in as that user. If you have a very small class or small lab, this may be all the users you need to register. Add Users Create a new user Add the new user to the jupyterhub_config.py file Log to JupyterHub in as the new user Summary Next Steps Adding new users to JupyterHub can be accomplished in a couple of different ways. Users can be added manually to the server from the command line, users can be added in JupyterHub with the Admin dashboard, and users can be added automatically when a user authenticates with a service like GitHub or Google. In this section, we are going to add users to the server manually. We will create a new user on the server and then log into JupyterHub as the new user. Open PuTTY and log into the server. Just to make sure, update the system before proceeding. $ sudo apt-get update $ sudo apt-get upgrade Shutdown JupyterHub and Nginx, then restart both of them. Let's make sure our system service functionality works correctly. $ sudo systemctl stop jupyterhub $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # check if active [Ctrl]+[c] to exit $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # check if active [Ctrl]+[c] to exit Point a web browser at our domain and log into JupyterHub as our non-root sudo user peter . Use the password we set for peter on the server. The JupyterHub login screen is shown below: You should see a couple files in the Jupyter notebook file browser. These are the same files that are in the non-root sudo user's ( peter ) home directory. At the Jupyter notebook file browser, choose [New] \u2192 [Python 3] Try writing a bit of Python code and running it. Imports for numpy and matplotlib should work normally. After messing around with a Jupyter notebook and making sure that imports and plots work correctly, shut down your notebook server. This action does not shut down the Digital Ocean server running JupyterHub, it just shuts down the server (running on the Digital Ocean server) that serves Jupyter notebooks for the user you logged in as. Click the [Control Pannel] button in the upper right-hand corner of the Jupyter notebook. This brings you to a web browser screen that shows buttons for [Stop My Server] and [My Server] and [Logout]. Click the [Stop My Server] button. Finally, logout by clicking the [Log Out] button in the upper right. This brings you back to the JupyterHub Sign in screen. The reason we want to log out is that we are going to create a new user and want to login as that user. If you don't log out, JupyterHub may start you as the user peter .","title":"Add Users"},{"location":"add_users/#create-a-new-user","text":"If you have a small class or a small lab, creating users one at a time at the command line and assigning them passwords might be all you need to do to get JupyterHub working for your small group. Next, we will create a new user on the server and log in as the new user. For a small group, you could repeat this process a couple times, and send out usernames and passwords to people in your group. On the server, create the new user with the adduser command. I called my new user gabby . $ sudo adduser gabby Set a new password and confirm: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully The user details can be skipped by pressing [Enter]. Then [Y] to complete the new user setup. Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n]","title":"Create a new user"},{"location":"add_users/#add-the-new-user-to-the-jupyterhub_configpy-file","text":"Now we need to add the new user to the jupyterhub_config.py file. So far the only users we have specified in the file is peter . Open up the jupyterhub_config.py file and edit the lines shown below. $ nano /etc/jupyterhub/jupyterhub_config.py Add the user 'gabby' to c.Authenticator.whitelist = { } # /etc/jupyterhub/jupyterhub_config.py ... # Users c.Authenticator.whitelist = {'peter','gabby'} c.Authenticator.admin_users = {'peter'} ... Save and close the file with [Ctrl]+[x] and [y]. Now restart Jupyterhub to make the changes take effect. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit","title":"Add the new user to the jupyterhub_config.py file"},{"location":"add_users/#log-to-jupyterhub-in-as-the-new-user","text":"Now browse to the domain name we set up before and log into JupyterHub as the new user gabby . Note the new user gabby doesn't have any files in their Jupyter notebook file browser. This is because the home directory of the user gabby is empty. If you create a new notebook, that notebook will be saved in the gabby home directory. Make sure to stop the server and logout as we did before by clicking [Control Panel] in the upper right and selecting [Stop My Server] and [Logout].","title":"Log to JupyterHub in as the new user"},{"location":"add_users/#summary","text":"In this section, we tested our JupyterHub deployment and added a new user to the server. After the new user was created, we added the new user to the jupyterhub_config.py file. Then we restarted JupyterHub and logged in as our new user.","title":"Summary"},{"location":"add_users/#next-steps","text":"The next step is to add Google authentication. This will allow students to log into our JupyterHub server with Google usernames and passwords.","title":"Next Steps"},{"location":"assignments_on_github/","text":"Assignments on GitHub Now we'll build a set of pre-constructed assignments and notes for each JupyterHub user. We'll save these assignments and notes to a GitHub repo. Assignments on GitHub Create a repo of assignments on GitHub.com Pull the repo down from GitHub.com to the local computer Create the assignments and notes Push the completed assignments and notes up to GiHub Summary Next Steps Create a repo of assignments on GitHub.com Log onto to GitHub.com, and create a new repo with the notes and assignments for the quarter. Make sure to select [Add .gitignore Python ] and select a license. Pull the repo down from GitHub.com to the local computer On a local computer, not the server, clone the GitHub repo. This allows us to work on the notes and assignments locally. # local computer $ mkdir ENGR101 $ cd ENGR101 $ git init $ git remote add origin https://github.com/username/reponame.git $ git pull origin master Create the assignments and notes On the local computer, not the server, build the assignment and notes for the quarter. I did this using Jupyter notebooks. Save all of the changes locally. Add any files that you don't want students to see to .gitignore. Push the completed assignments and notes up to GiHub Finally, add, commit, and push the changes up to GitHub. # local computer $ git add . $ commit -m \"added assignments and notes\" $ git push origin master Summary In this section, we built a set of notes and assignments for the quarter on GitHub. First a new repo was created on GitHub.com. A .gitignore file corresponding to Python and a license were added to the repo when the repo was created. Next we pulled to repo down to our local computer and built the assignments and notes. Finally we pushed the changes up to Github. Next Steps Next, we'll use a JupyterHub extension called nbgitpuller which copies the notes and assignments we just saved to GitHub into each students home folder when they log into JupyterHub.","title":"Assignments on GitHub"},{"location":"assignments_on_github/#assignments-on-github","text":"Now we'll build a set of pre-constructed assignments and notes for each JupyterHub user. We'll save these assignments and notes to a GitHub repo. Assignments on GitHub Create a repo of assignments on GitHub.com Pull the repo down from GitHub.com to the local computer Create the assignments and notes Push the completed assignments and notes up to GiHub Summary Next Steps","title":"Assignments on GitHub"},{"location":"assignments_on_github/#create-a-repo-of-assignments-on-githubcom","text":"Log onto to GitHub.com, and create a new repo with the notes and assignments for the quarter. Make sure to select [Add .gitignore Python ] and select a license.","title":"Create a repo of assignments on GitHub.com"},{"location":"assignments_on_github/#pull-the-repo-down-from-githubcom-to-the-local-computer","text":"On a local computer, not the server, clone the GitHub repo. This allows us to work on the notes and assignments locally. # local computer $ mkdir ENGR101 $ cd ENGR101 $ git init $ git remote add origin https://github.com/username/reponame.git $ git pull origin master","title":"Pull the repo down from GitHub.com to the local computer"},{"location":"assignments_on_github/#create-the-assignments-and-notes","text":"On the local computer, not the server, build the assignment and notes for the quarter. I did this using Jupyter notebooks. Save all of the changes locally. Add any files that you don't want students to see to .gitignore.","title":"Create the assignments and notes"},{"location":"assignments_on_github/#push-the-completed-assignments-and-notes-up-to-gihub","text":"Finally, add, commit, and push the changes up to GitHub. # local computer $ git add . $ commit -m \"added assignments and notes\" $ git push origin master","title":"Push the completed assignments and notes up to GiHub"},{"location":"assignments_on_github/#summary","text":"In this section, we built a set of notes and assignments for the quarter on GitHub. First a new repo was created on GitHub.com. A .gitignore file corresponding to Python and a license were added to the repo when the repo was created. Next we pulled to repo down to our local computer and built the assignments and notes. Finally we pushed the changes up to Github.","title":"Summary"},{"location":"assignments_on_github/#next-steps","text":"Next, we'll use a JupyterHub extension called nbgitpuller which copies the notes and assignments we just saved to GitHub into each students home folder when they log into JupyterHub.","title":"Next Steps"},{"location":"building_docs/","text":"Building Docs The documentation for this JupyterHub deployment was completed using mkdocs , the mkdocs-material theme and deployed on GitHub pages. The directory structure of the GitHub repo that houses the deployment files and docs looks like this: . \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 theme \u251c\u2500\u2500 etc \u2502 \u251c\u2500\u2500 jupyterhub \u2502 \u251c\u2500\u2500 nginx \u2502 \u2514\u2500\u2500 systemd \u2514\u2500\u2500 opt \u2514\u2500\u2500 miniconda3 Inside the docs/ directory is another docs/ subdirectory with all of markdown files that make up the documentation. There is also a mkdocs yaml file in the docs/ directory. When calling mkdocs commands from the command line, you need to be in the folder with the mkdocs.yml file. ./docs/ \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 docs/ \u2502 \u251c\u2500\u2500 images/ \u2502 \u251c\u2500\u2500 add_users.md \u2502 \u251c\u2500\u2500 assignments_on_github.md \u2502 \u251c\u2500\u2500 building_docs.md \u2502 \u251c\u2500\u2500 cookie_secret_proxy_auth_token.md \u2502 \u251c\u2500\u2500 custom_login_page.md \u2502 \u251c\u2500\u2500 dns_routing.md \u2502 \u251c\u2500\u2500 extra_configuration.md \u2502 \u251c\u2500\u2500 google_oauth.md \u2502 \u251c\u2500\u2500 index.md \u2502 \u251c\u2500\u2500 install_jupyterhub.md \u2502 \u251c\u2500\u2500 jupyterhub_config.md \u2502 \u251c\u2500\u2500 nbgitpuller_defaut_url.md \u2502 \u251c\u2500\u2500 nbgitpuller_plugin.md \u2502 \u251c\u2500\u2500 nginx_config.md \u2502 \u251c\u2500\u2500 nginx_install.md \u2502 \u251c\u2500\u2500 periodic_maintenance.md \u2502 \u251c\u2500\u2500 server_setup.md \u2502 \u251c\u2500\u2500 setup_and_tools.md \u2502 \u251c\u2500\u2500 slides \u2502 \u251c\u2500\u2500 ssh_keys.md \u2502 \u251c\u2500\u2500 ssl_cirtificates.md \u2502 \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 systemd.md \u2502 \u251c\u2500\u2500 useful_commands.md \u2502 \u2514\u2500\u2500 what_is_jupyterhub.md \u2514\u2500\u2500 theme \u251c\u2500\u2500 assets \u2514\u2500\u2500 partials To build the docs locally, make sure you have Python installed (I use Anaconda ). Start out by cloning the repo: git clone https://github.com/ProfessorKazarinoff/jupyterhub-engr101.git cd into the cloned repo, and create a virtual environment. Install the Python packages needed to build the docs. cd jupyterhub-engr101.git conda create -n jupyterhub python=3.7 conda activate jupyterhub (jupyterhub) pip install -r requirements.txt cd into the docs dir, and run mkdocs build and mkdocs serve cd docs ls # mkdocs.yml mkdocs build mkdocs serve Look at the built site on local host: http://localhost:8000/ Deploy to GitHub pages mkdocs gh-deploy","title":"Building the Docs"},{"location":"building_docs/#building-docs","text":"The documentation for this JupyterHub deployment was completed using mkdocs , the mkdocs-material theme and deployed on GitHub pages. The directory structure of the GitHub repo that houses the deployment files and docs looks like this: . \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 theme \u251c\u2500\u2500 etc \u2502 \u251c\u2500\u2500 jupyterhub \u2502 \u251c\u2500\u2500 nginx \u2502 \u2514\u2500\u2500 systemd \u2514\u2500\u2500 opt \u2514\u2500\u2500 miniconda3 Inside the docs/ directory is another docs/ subdirectory with all of markdown files that make up the documentation. There is also a mkdocs yaml file in the docs/ directory. When calling mkdocs commands from the command line, you need to be in the folder with the mkdocs.yml file. ./docs/ \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 docs/ \u2502 \u251c\u2500\u2500 images/ \u2502 \u251c\u2500\u2500 add_users.md \u2502 \u251c\u2500\u2500 assignments_on_github.md \u2502 \u251c\u2500\u2500 building_docs.md \u2502 \u251c\u2500\u2500 cookie_secret_proxy_auth_token.md \u2502 \u251c\u2500\u2500 custom_login_page.md \u2502 \u251c\u2500\u2500 dns_routing.md \u2502 \u251c\u2500\u2500 extra_configuration.md \u2502 \u251c\u2500\u2500 google_oauth.md \u2502 \u251c\u2500\u2500 index.md \u2502 \u251c\u2500\u2500 install_jupyterhub.md \u2502 \u251c\u2500\u2500 jupyterhub_config.md \u2502 \u251c\u2500\u2500 nbgitpuller_defaut_url.md \u2502 \u251c\u2500\u2500 nbgitpuller_plugin.md \u2502 \u251c\u2500\u2500 nginx_config.md \u2502 \u251c\u2500\u2500 nginx_install.md \u2502 \u251c\u2500\u2500 periodic_maintenance.md \u2502 \u251c\u2500\u2500 server_setup.md \u2502 \u251c\u2500\u2500 setup_and_tools.md \u2502 \u251c\u2500\u2500 slides \u2502 \u251c\u2500\u2500 ssh_keys.md \u2502 \u251c\u2500\u2500 ssl_cirtificates.md \u2502 \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 systemd.md \u2502 \u251c\u2500\u2500 useful_commands.md \u2502 \u2514\u2500\u2500 what_is_jupyterhub.md \u2514\u2500\u2500 theme \u251c\u2500\u2500 assets \u2514\u2500\u2500 partials To build the docs locally, make sure you have Python installed (I use Anaconda ). Start out by cloning the repo: git clone https://github.com/ProfessorKazarinoff/jupyterhub-engr101.git cd into the cloned repo, and create a virtual environment. Install the Python packages needed to build the docs. cd jupyterhub-engr101.git conda create -n jupyterhub python=3.7 conda activate jupyterhub (jupyterhub) pip install -r requirements.txt cd into the docs dir, and run mkdocs build and mkdocs serve cd docs ls # mkdocs.yml mkdocs build mkdocs serve Look at the built site on local host: http://localhost:8000/ Deploy to GitHub pages mkdocs gh-deploy","title":"Building Docs"},{"location":"cookie_secret_proxy_auth_token/","text":"Create a Cookie Secret and Proxy Auth Token In addition to an SSL certificate, the Jupyter Hub docs on security basics specify that a cookie secret and poxy auth token be created. Create a Cookie Secret and Proxy Auth Token Create a Cookie Secret Create Proxy Auth Token Create dhparam.pem Summary Next Steps Create a Cookie Secret According to the JupyterHub docs, the cookie secret file should be saved in the /srv/jupyterhub directory. cd into the /srv directory and mkdir a new jupyterhub subdirectory. Note you need to use sudo to create a subdirectory in /srv . $ cd /srv $ sudo mkdir jupyterhub $ cd jupyterhub Next use touch to create the jupyterhub_cookie_secret file. Write to the file using openssl . Change the final file permissions to 600 as noted in the JupyterHub docs. $ pwd /srv/jupyterhub $ sudo touch jupyterhub_cookie_secret $ sudo chown :sudo jupyterhub_cookie_secret $ sudo chmod g+rw jupyterhub_cookie_secret $ sudo openssl rand -hex 32 > jupyterhub_cookie_secretl $ sudo chmod 600 jupyterhub_cookie_secret $ls -la -rw------- 1 root sudo 65 Feb 6 20:37 jupyterhub_cookie_secret I had trouble with the cookie secret file because I missed where the jupyterhub docs show: The file must not be readable by group or other or the server won\u2019t start. The recommended permissions for the cookie secret file are 600 (owner-only rw). After you create the cookie secret file, note of the file's location. We'll add the jupyterhub_cookie_secret file location to our JupyterHub configuration. Create Proxy Auth Token To generate the proxy auth token, use the same set of commands used to create the cookie secret, except point to a different file called proxy_auth_token . $ pwd /srv/jupyterhub $ sudo touch proxy_auth_token $ sudo chown :sudo proxy_auth_token $ sudo chmod g+rw proxy_auth_token $ sudo openssl rand -hex 32 > proxy_auth_token $ sudo chmod 600 proxy_auth_token $ls -la -rw------- 1 root sudo 65 Feb 6 20:37 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Feb 6 20:37 proxy_auth_token Now, when we list the contents of ~/srv/jupyterhub we see: /srv/jupyterhub/ \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token Create dhparam.pem Let's also generate a dhparam.pem file. I'm still not exactly sure what the dhparam.pem file is, it has something to do with security. dhparam.pem will be incorporated into our Nginx config file later on. We'll use the same set of commands we used to create the cookie secret and proxy auth token. The part which is different is the openssl dhparam command generates the `.pem file . It takes a minute or two for openssl to do it's work. Finally we modify the permissions again to 600 (owner-only rw). Note the location of the dhparam.pem file as we will add it to the Nginx config file. $ pwd /srv/jupyterhub $ sudo touch dhparam.pem $ sudo chown :sudo dhparam.pem $ sudo chmod g+rw dhparam.pem $ sudo openssl dhparam -out /srv/jupyterhub/dhparam.pem 2048 # wait a minute or two $ sudo chmod 600 dhparam.pem $ ls -la -rw------- 1 root sudo 424 Feb 6 20:37 dhparam.pem -rw------- 1 root sudo 65 Feb 6 20:37 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Feb 6 20:37 proxy_auth_token We now have three files in the /srv/jupyterhub/ directory. The jupyterhub_cookie_secret and proxy_auth_token will be referenced in the jupyterhub_config.py file. The dhparam.pem file will be referenced in the nginx.conf file. /srv/jupyterhub/ \u251c\u2500\u2500 dhparam.pem \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token Summary In this section, we created a jupyterhub directory inside /srv . Inside that directory we created three files using the openssl utility: jupyterhub_cookie_secret proxy_auth_token dhparam.pem Each of these three files have their permissions set to 600 . Next Steps The next step is to install Nginx on the server.","title":"Cookie Secret and Proxy Auth Token"},{"location":"cookie_secret_proxy_auth_token/#create-a-cookie-secret-and-proxy-auth-token","text":"In addition to an SSL certificate, the Jupyter Hub docs on security basics specify that a cookie secret and poxy auth token be created. Create a Cookie Secret and Proxy Auth Token Create a Cookie Secret Create Proxy Auth Token Create dhparam.pem Summary Next Steps","title":"Create a Cookie Secret and Proxy Auth Token"},{"location":"cookie_secret_proxy_auth_token/#create-a-cookie-secret","text":"According to the JupyterHub docs, the cookie secret file should be saved in the /srv/jupyterhub directory. cd into the /srv directory and mkdir a new jupyterhub subdirectory. Note you need to use sudo to create a subdirectory in /srv . $ cd /srv $ sudo mkdir jupyterhub $ cd jupyterhub Next use touch to create the jupyterhub_cookie_secret file. Write to the file using openssl . Change the final file permissions to 600 as noted in the JupyterHub docs. $ pwd /srv/jupyterhub $ sudo touch jupyterhub_cookie_secret $ sudo chown :sudo jupyterhub_cookie_secret $ sudo chmod g+rw jupyterhub_cookie_secret $ sudo openssl rand -hex 32 > jupyterhub_cookie_secretl $ sudo chmod 600 jupyterhub_cookie_secret $ls -la -rw------- 1 root sudo 65 Feb 6 20:37 jupyterhub_cookie_secret I had trouble with the cookie secret file because I missed where the jupyterhub docs show: The file must not be readable by group or other or the server won\u2019t start. The recommended permissions for the cookie secret file are 600 (owner-only rw). After you create the cookie secret file, note of the file's location. We'll add the jupyterhub_cookie_secret file location to our JupyterHub configuration.","title":"Create a Cookie Secret"},{"location":"cookie_secret_proxy_auth_token/#create-proxy-auth-token","text":"To generate the proxy auth token, use the same set of commands used to create the cookie secret, except point to a different file called proxy_auth_token . $ pwd /srv/jupyterhub $ sudo touch proxy_auth_token $ sudo chown :sudo proxy_auth_token $ sudo chmod g+rw proxy_auth_token $ sudo openssl rand -hex 32 > proxy_auth_token $ sudo chmod 600 proxy_auth_token $ls -la -rw------- 1 root sudo 65 Feb 6 20:37 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Feb 6 20:37 proxy_auth_token Now, when we list the contents of ~/srv/jupyterhub we see: /srv/jupyterhub/ \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token","title":"Create Proxy Auth Token"},{"location":"cookie_secret_proxy_auth_token/#create-dhparampem","text":"Let's also generate a dhparam.pem file. I'm still not exactly sure what the dhparam.pem file is, it has something to do with security. dhparam.pem will be incorporated into our Nginx config file later on. We'll use the same set of commands we used to create the cookie secret and proxy auth token. The part which is different is the openssl dhparam command generates the `.pem file . It takes a minute or two for openssl to do it's work. Finally we modify the permissions again to 600 (owner-only rw). Note the location of the dhparam.pem file as we will add it to the Nginx config file. $ pwd /srv/jupyterhub $ sudo touch dhparam.pem $ sudo chown :sudo dhparam.pem $ sudo chmod g+rw dhparam.pem $ sudo openssl dhparam -out /srv/jupyterhub/dhparam.pem 2048 # wait a minute or two $ sudo chmod 600 dhparam.pem $ ls -la -rw------- 1 root sudo 424 Feb 6 20:37 dhparam.pem -rw------- 1 root sudo 65 Feb 6 20:37 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Feb 6 20:37 proxy_auth_token We now have three files in the /srv/jupyterhub/ directory. The jupyterhub_cookie_secret and proxy_auth_token will be referenced in the jupyterhub_config.py file. The dhparam.pem file will be referenced in the nginx.conf file. /srv/jupyterhub/ \u251c\u2500\u2500 dhparam.pem \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token","title":"Create dhparam.pem"},{"location":"cookie_secret_proxy_auth_token/#summary","text":"In this section, we created a jupyterhub directory inside /srv . Inside that directory we created three files using the openssl utility: jupyterhub_cookie_secret proxy_auth_token dhparam.pem Each of these three files have their permissions set to 600 .","title":"Summary"},{"location":"cookie_secret_proxy_auth_token/#next-steps","text":"The next step is to install Nginx on the server.","title":"Next Steps"},{"location":"custom_login_page/","text":"Custom Login Page Now that we completed the Google OAuth configuration, our JupyterHub login page looks like this: But our college login page looks like this: For users to feel comfortable logging into our JupyterHub server, we'll make our JupyterHub login page look more like the college login page. Custom Login Page Create a templates directory and populate it with Jinja templates Modify login.html Modify jupyterhub_config.py Restart JupyterHub and view changes Style the login page with css Restart JupyterHub Summary Next Steps Create a templates directory and populate it with Jinja templates Customizing the login page was a time consuming and fussy task. It involved a lot of messing around with css and html, plus some knowledge about how jinja templates work. First, a set of custom jinja templates need to be created. When JupyterHub runs, there is a directory of jinja templates that build the html users see when they browse to the login page. The jinga templates that build the login page are buried deep in the JupyterHub package code. For my JupyterHub installation on the server, I found the jinja template files in the /opt/miniconda3/envs/jupyterhub/share/jupyterhub/templates/ directory. If you aren't using a virtual environment, the JupyterHub package directory name will likely be different. The contents of the directory that contains the jinja templates is below. /opt/anaconda3/envs/pkgs/jupyterhub/share/jupyterhub/templates/ \u251c\u2500\u2500 404.html \u251c\u2500\u2500 admin.html \u251c\u2500\u2500 error.html \u251c\u2500\u2500 home.html \u251c\u2500\u2500 login.html \u251c\u2500\u2500 logout.html \u251c\u2500\u2500 page.html \u251c\u2500\u2500 spawn.html \u251c\u2500\u2500 spawn_pending.html \u2514\u2500\u2500 token.html Next, we will copy these templates into a new /etc/jupyterhub/templates directory. Once copied, we can modify the templates and create a new JupyterHub login page. login.html is the file we'll customize. $ cd /opt/miniconda3/envs/jupyterhub/share/jupyterhub $ ls static templates $ cp -R templates /etc/jupyterhub/templates/ $ cd /etc/jupyterhub/templates $ ls 404.html error.html login.html oauth.html spawn.html stop_pending.html admin.html home.html logout.html page.html spawn_pending.html token.html Modify login.html Open up the login.html file with a local code editor and modify login.html with any html you want to show up when a user goes to the JupyterHub site. This is what the user will see first thing, before they have logged in. I messed around for WAY to long trying to get my custom login page to look like our college login page. An important piece of html that needs to stay in the login.html file is the <a> tag that links to the authentication url. The complete tag is detailed below: <!\u2013\u2013 login.html \u2013\u2013> <a role=\"button\" class=\"btn btn-jupyter btn-lg\" href=\"/hub/oauth_login?next=\"> Sign in with Portland Community College </a> I also kept in the jinga tag at the top of the file that brings in all of the formatting from login.html 's parent template page.html . <!\u2013\u2013 login.html \u2013\u2013> {% extends \"page.html\" %} All the changes I made to the login template were inside the \"login\" block ( {% block login %} ) of login.html . {% block login %} <!\u2013\u2013 make changes here \u2013\u2013> {% endblock login %} You can find my complete login.html file on GitHub here . I used FileZilla, an SFTP Windows App, to move the login.html file from my local computer to the server. To use FileZilla, Select [File] \u2192 [Site Manager]. Select [SFTP], add the server IP address, username, and select [Log in Type] \u2192 [Key File]. FileZilla settings are below: Modify jupyterhub_config.py Now we need to modify the jupyterhub_config.py file so that our new set of custom jinja templates are used instead of the default jinja templates. I initially had a problem, because I set the directory path of the custom templates as templates . This caused the login page to not work as expected. When I changed the directory path to templates/ the problem was resolved. # /etc/jupyterhub/jupyterhub_config.py ... # sets a custom html template at the login screen. c.JupyterHub.template_paths = ['/etc/jupyterhub/templates/'] ... Restart JupyterHub and view changes With changes to the login.html file complete, and the template_paths= set in jupyterhub_config.py correctly, we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit The new login page is below: The login works, but the issue now is that without css, the page looks plain and doesn't really look like our college login page: Therefore, we need to add some css styling to the page. Style the login page with css Finally, the style.min.css file needs to be modified so that the login page styling looks a little more like our college login page. CSS another thing I messed around with for a long time, a WAY to long time... I couldn't figure out a way to get JupyterHub to use a custom .css file. I tried creating a .css file in the new custom templates directory, but JupyterHub wouldn't copy it as a static asset when the server launched. I also tried putting a separate .css file deep inside of the JupyterHub package code. When the server ran, it seemed to copy the custom .css file (I could see the custom .css file using chrome's inspect element tool). But for some reason the custom .css file would be blank when server serve was running, even though the custom .css file contained a whole bunch of css code when viewed deep in the JupyterHub package code. The solution I finally got to work was to modify the style.min.css file itself that JupyterHub uses. This file is buried deep in the JupyterHub package code: /opt/miniconda3/envs/jupyterhub/share/jupyterhub/static/css \u251c\u2500\u2500 style.min.css \u2514\u2500\u2500 style.min.css.map Modify the style.min.css file to include all the custom css styling desired (find my complete css file on GitHub here I used FileZilla again to move over the file. style.min.css is a pretty big file and copying and pasting into PuTTY would probably lead to a lot of errors. Restart JupyterHub With changes to the login.html file and style.min.css file complete, we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit Below is the look of the modified login page in all it's custom html and css glory: Summary In this section, we created a custom login page that looks a lot like our college login page. First we copied over the jinja templates JupyterHub uses to build the login page into a separate directory. Then we modified the html code in the login.html template. Next, we modified the JupyterHub configuration to use our custom template. Finally, we modified a special css file buried deep in the JuypyterHub package code. The end result is a JupyterHub login page that looks a lot like our college login page. Next Steps The next step is to add a set of notes and assignments to GitHub. We'll use these notes and assignments for the class. After we save the notes and assignments to GitHub, we will use a JupyterHub extension to pull the assignments and notes down for each student (each JupyterHub user).","title":"Custom Login Page"},{"location":"custom_login_page/#custom-login-page","text":"Now that we completed the Google OAuth configuration, our JupyterHub login page looks like this: But our college login page looks like this: For users to feel comfortable logging into our JupyterHub server, we'll make our JupyterHub login page look more like the college login page. Custom Login Page Create a templates directory and populate it with Jinja templates Modify login.html Modify jupyterhub_config.py Restart JupyterHub and view changes Style the login page with css Restart JupyterHub Summary Next Steps","title":"Custom Login Page"},{"location":"custom_login_page/#create-a-templates-directory-and-populate-it-with-jinja-templates","text":"Customizing the login page was a time consuming and fussy task. It involved a lot of messing around with css and html, plus some knowledge about how jinja templates work. First, a set of custom jinja templates need to be created. When JupyterHub runs, there is a directory of jinja templates that build the html users see when they browse to the login page. The jinga templates that build the login page are buried deep in the JupyterHub package code. For my JupyterHub installation on the server, I found the jinja template files in the /opt/miniconda3/envs/jupyterhub/share/jupyterhub/templates/ directory. If you aren't using a virtual environment, the JupyterHub package directory name will likely be different. The contents of the directory that contains the jinja templates is below. /opt/anaconda3/envs/pkgs/jupyterhub/share/jupyterhub/templates/ \u251c\u2500\u2500 404.html \u251c\u2500\u2500 admin.html \u251c\u2500\u2500 error.html \u251c\u2500\u2500 home.html \u251c\u2500\u2500 login.html \u251c\u2500\u2500 logout.html \u251c\u2500\u2500 page.html \u251c\u2500\u2500 spawn.html \u251c\u2500\u2500 spawn_pending.html \u2514\u2500\u2500 token.html Next, we will copy these templates into a new /etc/jupyterhub/templates directory. Once copied, we can modify the templates and create a new JupyterHub login page. login.html is the file we'll customize. $ cd /opt/miniconda3/envs/jupyterhub/share/jupyterhub $ ls static templates $ cp -R templates /etc/jupyterhub/templates/ $ cd /etc/jupyterhub/templates $ ls 404.html error.html login.html oauth.html spawn.html stop_pending.html admin.html home.html logout.html page.html spawn_pending.html token.html","title":"Create a templates directory and populate it with Jinja templates"},{"location":"custom_login_page/#modify-loginhtml","text":"Open up the login.html file with a local code editor and modify login.html with any html you want to show up when a user goes to the JupyterHub site. This is what the user will see first thing, before they have logged in. I messed around for WAY to long trying to get my custom login page to look like our college login page. An important piece of html that needs to stay in the login.html file is the <a> tag that links to the authentication url. The complete tag is detailed below: <!\u2013\u2013 login.html \u2013\u2013> <a role=\"button\" class=\"btn btn-jupyter btn-lg\" href=\"/hub/oauth_login?next=\"> Sign in with Portland Community College </a> I also kept in the jinga tag at the top of the file that brings in all of the formatting from login.html 's parent template page.html . <!\u2013\u2013 login.html \u2013\u2013> {% extends \"page.html\" %} All the changes I made to the login template were inside the \"login\" block ( {% block login %} ) of login.html . {% block login %} <!\u2013\u2013 make changes here \u2013\u2013> {% endblock login %} You can find my complete login.html file on GitHub here . I used FileZilla, an SFTP Windows App, to move the login.html file from my local computer to the server. To use FileZilla, Select [File] \u2192 [Site Manager]. Select [SFTP], add the server IP address, username, and select [Log in Type] \u2192 [Key File]. FileZilla settings are below:","title":"Modify login.html"},{"location":"custom_login_page/#modify-jupyterhub_configpy","text":"Now we need to modify the jupyterhub_config.py file so that our new set of custom jinja templates are used instead of the default jinja templates. I initially had a problem, because I set the directory path of the custom templates as templates . This caused the login page to not work as expected. When I changed the directory path to templates/ the problem was resolved. # /etc/jupyterhub/jupyterhub_config.py ... # sets a custom html template at the login screen. c.JupyterHub.template_paths = ['/etc/jupyterhub/templates/'] ...","title":"Modify jupyterhub_config.py"},{"location":"custom_login_page/#restart-jupyterhub-and-view-changes","text":"With changes to the login.html file complete, and the template_paths= set in jupyterhub_config.py correctly, we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit The new login page is below: The login works, but the issue now is that without css, the page looks plain and doesn't really look like our college login page: Therefore, we need to add some css styling to the page.","title":"Restart JupyterHub and view changes"},{"location":"custom_login_page/#style-the-login-page-with-css","text":"Finally, the style.min.css file needs to be modified so that the login page styling looks a little more like our college login page. CSS another thing I messed around with for a long time, a WAY to long time... I couldn't figure out a way to get JupyterHub to use a custom .css file. I tried creating a .css file in the new custom templates directory, but JupyterHub wouldn't copy it as a static asset when the server launched. I also tried putting a separate .css file deep inside of the JupyterHub package code. When the server ran, it seemed to copy the custom .css file (I could see the custom .css file using chrome's inspect element tool). But for some reason the custom .css file would be blank when server serve was running, even though the custom .css file contained a whole bunch of css code when viewed deep in the JupyterHub package code. The solution I finally got to work was to modify the style.min.css file itself that JupyterHub uses. This file is buried deep in the JupyterHub package code: /opt/miniconda3/envs/jupyterhub/share/jupyterhub/static/css \u251c\u2500\u2500 style.min.css \u2514\u2500\u2500 style.min.css.map Modify the style.min.css file to include all the custom css styling desired (find my complete css file on GitHub here I used FileZilla again to move over the file. style.min.css is a pretty big file and copying and pasting into PuTTY would probably lead to a lot of errors.","title":"Style the login page with css"},{"location":"custom_login_page/#restart-jupyterhub","text":"With changes to the login.html file and style.min.css file complete, we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit Below is the look of the modified login page in all it's custom html and css glory:","title":"Restart JupyterHub"},{"location":"custom_login_page/#summary","text":"In this section, we created a custom login page that looks a lot like our college login page. First we copied over the jinja templates JupyterHub uses to build the login page into a separate directory. Then we modified the html code in the login.html template. Next, we modified the JupyterHub configuration to use our custom template. Finally, we modified a special css file buried deep in the JuypyterHub package code. The end result is a JupyterHub login page that looks a lot like our college login page.","title":"Summary"},{"location":"custom_login_page/#next-steps","text":"The next step is to add a set of notes and assignments to GitHub. We'll use these notes and assignments for the class. After we save the notes and assignments to GitHub, we will use a JupyterHub extension to pull the assignments and notes down for each student (each JupyterHub user).","title":"Next Steps"},{"location":"dns_routing/","text":"DNS Routing After we verify JupyterHub is working with all the default settings, we need to link a domain name our Digital Ocean server. DNS Routing Link domain name to server IP address Google Domains Digital Ocean DNS Summary Next Steps Link domain name to server IP address When we started JupyterHub in the previous step, it ran, we could log in, and we could run Python code. What's not to like, right? Well, security is the big problem. In the initial setup, JupyterHub was running under regular http, not https. With a web application that has usernames and passwords, like JupyterHub, having https and SSL security is best (or maybe mandatory!). In order to use https, we need to generate an SSL certificate. The SSL certificate should correspond to the domain name linked to our server. Therefore, the first step on our way to SSL security, is purchasing a domain name and pointing the domain name it at the Digital Ocean DNS servers. Then we'll link the domain name to our JupyterHub server. Google Domains I purchased the domain for this JupyterHub deployment from Google Domains . The domain cost $12/year (which seems pretty reasonable) and Google domains makes set up pretty easy. After purchasing the domain, I added the Digital Ocean DNS servers as a set of custom name servers to my domain options on Google Domains. To add a set of custom name servers using the Google Domains dashboard, click the two bars icon under the [DNS] header. This brings up a page where we can enter in the Digital Ocean DNS server addresses. The name servers to add are: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Make sure to click the [Use custom name servers] radio button and click [Save]. Digital Ocean DNS Now we are going to set our domain to link to the IP address of our server on Digital Ocean. Log into Digital Ocean and in the upper right select [Create] \u2192 [Domains/DNS] In the [Enter domain] field, type in the domain name without http, but including .com (or .edu/.org/.net) such as mydomain.org , then click [Add Domain]. This brings up a panel where we can add a DNS record. I want the JupyterHub server to have the web address of the domain I purchased, no subdomains like notebooks.mydomain.com for this installation of JupyterHub. I entered @ in the text field labeled [Enter @ or hostname]. Then selected the Droplet (our JupyterHub server) that the web address will route to. Click [Create Record] to add the DNS record. I also entered a www in the text field labeled [Enter @ or hostname]. Then selected the Droplet (our JupyterHub server) that the web address will route to. Again, click [Create Record] to add the DNS record. After completing this step, there will be a couple of new DNS records. The results will look something like the screen capture below: It takes a couple minutes for the DNS switchover to complete. https://www.whatsmydns.net can be used to check the NS and A records of your domain and see if the domain name is getting through. The first time I set up DNS on Digital Ocean, I added the custom DNS servers to Google Domains but neglected to select the [use custom name servers] radio button on the Google Domains dashboard. It looked like the domain was routing to Digital Ocean, but actually the domain was just staying with Google. Once I clicked the [use custom name servers] radio button and waited a couple minutes, the change over happened. It did take a bit of time though; not hours, but more than a few minutes. Summary In this section, we purchased a domain name from Google Domains and linked the domain name to the Digital Ocean name servers. Next, we logged into Digital Ocean and added our newly purchased domain to our Digital Ocean account. Finally we created DNS records for @ and www in the Digtial Ocean Domains/DNS dashboard. As a result, there is a custom domain linked to our JupyterHub server. Next Steps The next step is to obtain an SSL certificate so we can use SSL security and https instead of http.","title":"DNS Routing"},{"location":"dns_routing/#dns-routing","text":"After we verify JupyterHub is working with all the default settings, we need to link a domain name our Digital Ocean server. DNS Routing Link domain name to server IP address Google Domains Digital Ocean DNS Summary Next Steps","title":"DNS Routing"},{"location":"dns_routing/#link-domain-name-to-server-ip-address","text":"When we started JupyterHub in the previous step, it ran, we could log in, and we could run Python code. What's not to like, right? Well, security is the big problem. In the initial setup, JupyterHub was running under regular http, not https. With a web application that has usernames and passwords, like JupyterHub, having https and SSL security is best (or maybe mandatory!). In order to use https, we need to generate an SSL certificate. The SSL certificate should correspond to the domain name linked to our server. Therefore, the first step on our way to SSL security, is purchasing a domain name and pointing the domain name it at the Digital Ocean DNS servers. Then we'll link the domain name to our JupyterHub server.","title":"Link domain name to server IP address"},{"location":"dns_routing/#google-domains","text":"I purchased the domain for this JupyterHub deployment from Google Domains . The domain cost $12/year (which seems pretty reasonable) and Google domains makes set up pretty easy. After purchasing the domain, I added the Digital Ocean DNS servers as a set of custom name servers to my domain options on Google Domains. To add a set of custom name servers using the Google Domains dashboard, click the two bars icon under the [DNS] header. This brings up a page where we can enter in the Digital Ocean DNS server addresses. The name servers to add are: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Make sure to click the [Use custom name servers] radio button and click [Save].","title":"Google Domains"},{"location":"dns_routing/#digital-ocean-dns","text":"Now we are going to set our domain to link to the IP address of our server on Digital Ocean. Log into Digital Ocean and in the upper right select [Create] \u2192 [Domains/DNS] In the [Enter domain] field, type in the domain name without http, but including .com (or .edu/.org/.net) such as mydomain.org , then click [Add Domain]. This brings up a panel where we can add a DNS record. I want the JupyterHub server to have the web address of the domain I purchased, no subdomains like notebooks.mydomain.com for this installation of JupyterHub. I entered @ in the text field labeled [Enter @ or hostname]. Then selected the Droplet (our JupyterHub server) that the web address will route to. Click [Create Record] to add the DNS record. I also entered a www in the text field labeled [Enter @ or hostname]. Then selected the Droplet (our JupyterHub server) that the web address will route to. Again, click [Create Record] to add the DNS record. After completing this step, there will be a couple of new DNS records. The results will look something like the screen capture below: It takes a couple minutes for the DNS switchover to complete. https://www.whatsmydns.net can be used to check the NS and A records of your domain and see if the domain name is getting through. The first time I set up DNS on Digital Ocean, I added the custom DNS servers to Google Domains but neglected to select the [use custom name servers] radio button on the Google Domains dashboard. It looked like the domain was routing to Digital Ocean, but actually the domain was just staying with Google. Once I clicked the [use custom name servers] radio button and waited a couple minutes, the change over happened. It did take a bit of time though; not hours, but more than a few minutes.","title":"Digital Ocean DNS"},{"location":"dns_routing/#summary","text":"In this section, we purchased a domain name from Google Domains and linked the domain name to the Digital Ocean name servers. Next, we logged into Digital Ocean and added our newly purchased domain to our Digital Ocean account. Finally we created DNS records for @ and www in the Digtial Ocean Domains/DNS dashboard. As a result, there is a custom domain linked to our JupyterHub server.","title":"Summary"},{"location":"dns_routing/#next-steps","text":"The next step is to obtain an SSL certificate so we can use SSL security and https instead of http.","title":"Next Steps"},{"location":"draw_dot_IO_extension/","text":"Draw.IO Extension In my ENGR114 class, students learn how to construct flow charts that describe the way a program runs. Students also use flowcharts to plan how a program will run. We can provide students access to a flow chart drawing program right in JupyterHub called Draw.IO . Draw.IO can be added to our JuptyerHub deployment as a JupyterLab extension. Draw.IO Extension Install nodejs Install Draw.IO extension for JupyterLub Restart JupyterHub and test it out Summary Install nodejs Ensure that nodejs is installed in the (jupyterhub) virtual environment. Nodejs is needed to install the Draw.IO JupyterLab extension. $ sudo systemctl stop jupyterhub $ conda activate jupyterhub (jupyterhub)$ conda install -c conda-forge nodejs Install Draw.IO extension for JupyterLub Type another conda install line to install the Draw.IO extension for JupyterLab. (jupyterhub)$ jupyter labextension install jupyterlab-drawio Restart JupyterHub and test it out $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]+[c] to exit Below are some screen captures of the Draw.io extension in action. Students need to click the [Diagram] icon in the JupyterLab [Launcher] window to open a new Draw.IO drawing. Summary Draw.io is a drawing program students can use to create flow charts. Draw.io can be installed as a JupyterLab extension in our JupyterHub deployment. To install Draw.io into JupyterHub, first install nodejs and then install the Draw.io extension.","title":"Draw.IO extension"},{"location":"draw_dot_IO_extension/#drawio-extension","text":"In my ENGR114 class, students learn how to construct flow charts that describe the way a program runs. Students also use flowcharts to plan how a program will run. We can provide students access to a flow chart drawing program right in JupyterHub called Draw.IO . Draw.IO can be added to our JuptyerHub deployment as a JupyterLab extension. Draw.IO Extension Install nodejs Install Draw.IO extension for JupyterLub Restart JupyterHub and test it out Summary","title":"Draw.IO Extension"},{"location":"draw_dot_IO_extension/#install-nodejs","text":"Ensure that nodejs is installed in the (jupyterhub) virtual environment. Nodejs is needed to install the Draw.IO JupyterLab extension. $ sudo systemctl stop jupyterhub $ conda activate jupyterhub (jupyterhub)$ conda install -c conda-forge nodejs","title":"Install nodejs"},{"location":"draw_dot_IO_extension/#install-drawio-extension-for-jupyterlub","text":"Type another conda install line to install the Draw.IO extension for JupyterLab. (jupyterhub)$ jupyter labextension install jupyterlab-drawio","title":"Install Draw.IO extension for JupyterLub"},{"location":"draw_dot_IO_extension/#restart-jupyterhub-and-test-it-out","text":"$ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]+[c] to exit Below are some screen captures of the Draw.io extension in action. Students need to click the [Diagram] icon in the JupyterLab [Launcher] window to open a new Draw.IO drawing.","title":"Restart JupyterHub and test it out"},{"location":"draw_dot_IO_extension/#summary","text":"Draw.io is a drawing program students can use to create flow charts. Draw.io can be installed as a JupyterLab extension in our JupyterHub deployment. To install Draw.io into JupyterHub, first install nodejs and then install the Draw.io extension.","title":"Summary"},{"location":"extra_configuration/","text":"Extra Configuration In this section, we will go over some extra configuration settings we can set in jupyterhub_config.py to help our JupyterHub deployment hum along and help if students forget to logout or too many student try and log in at the same time. Extra Configuration Configuration Options Cull Idle Servers Modify jupyterhub_config.py and upload to server Summary Additional Extras Configuration Options In the JupyterHub docs, there is a list of configuration options and descriptions: https://jupyterhub.readthedocs.io/en/stable/api/app.html A couple configuration options in the list seem like good ideas: The class has 24 students, plus one instructor. Given that class size, I think 26 is a good number for the maximum that can use JupyterHub the same time. config c.JupyterHub.active_server_limit = Int(0) # Maximum number of concurrent servers that can be active at a time. Having too many users log in all at the same time can overload the server. Let's set this as 13, so half of the class can log in at the same time. config c.JupyterHub.concurrent_spawn_limit = Int(100) Maximum number of concurrent users that can be spawning at a time. A couple settings relate to shutting down the hub and if user servers shut down too. I want it set so that if I shut down the hub, all the user servers are shut down too. config c.JupyterHub.cleanup_proxy = Bool(True) # Whether to shutdown the proxy when the Hub shuts down. config c.JupyterHub.cleanup_servers = Bool(True) # Whether to shutdown single-user servers when the Hub shuts down. Cull Idle Servers A problem with the first two JupyterHub deployments was that some students would not shut down their server when they were done working. Then twenty or so servers would all keep running all the time. This script from the JupyterHub Examples repo looks like it might help: https://github.com/jupyterhub/jupyterhub/tree/master/examples/cull-idle To get the cull_idle_servers.py script to run as a JupyterHub service, it looks like you need to add the following to jupyterhub_config.py . (Based on this page in the JupyterHub docs) # /etc/jupyterhub/jupyterhub_config.py import sys ... # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] Put cull_idle_servers.py (found here ) in /etc/jupyterhub/ . Make sure dateutil is intalled in the jupyterhub virtual env. Try >>> import dateutil >>> dateutil.__version__ (using the (jupyterhub) virtual env. Make sure to add import sys to the top of jupyterhub_config.py . Restart JupyterHub. Check for errors. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit If it seems like the cull_idle_servers.py script isn't working, try running cull_idle_servers.py from the command line to see if there are any errors. Make sure you are in the (jupyterhub) virtual environment when you run the script. The script will look for the JUPYTERHUB_API_TOKEN environment variable. An API token can be aquired by logging into JupyterHub (like a regular student) and clicking the [Token] menu from the home page that has the [Stop My Server] and [My Server] buttons. Click [Request new API token] and copy the API token. Then run the lines below (replace ```XXXX```` with your actual API token): $ export JUPYTERHUB_API_TOKEN='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' $ echo $JUPYTERHUB_API_TOKEN # API token is printed $ cd /etc/jupyterhub $ conda activate jupyterhub (jupyterhub)$ python cull_idle_servers.py --timeout=60 --url=http://127.0.0.1:8081/hub/api # check for errors Modify jupyterhub_config.py and upload to server The additions made to jupyterhub_config.py are shown below: # /etc/jupyterhub/jupyterhub_config.py ... ## Extra Configuration # Maximum number of concurrent servers that can be active at a time c.JupyterHub.active_server_limit = 26 # Maximum number of concurrent users that can be spawning at a time c.JupyterHub.concurrent_spawn_limit = 13 # Whether to shutdown the proxy when the Hub shuts down. c.JupyterHub.cleanup_proxy = True # Whether to shutdown single-user servers when the Hub shuts down. c.JupyterHub.cleanup_servers = True # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] ... I made these changes in jupyterhub_config.py locally and then used FileZilla to upload the modified config file to the server. After the modified jupyterhub_config.py file is uploaded to the server, restart JupyterHub and make sure there no errors. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Summary In this section we added a few extra configuration options to the jupyterhub_config.py file. A few extra configuration options we included were to limit the number of servers that can run at the same time and limit the amount of servers that can spawn at the same time. We also added a cull_idle_servers.py script to the server which will shut down idle servers if a student has not used them in a while. This involved copying the script locally from GitHub, then uploading the script on the server in the /etc/jupyterhub/ directory. The jupyterhub_config.py file has to be modified so that sys is imported and the cull_idle_servers.py script runs and a JupyterHub service Finally we uploaded the modified jupyterhubconfig.py configuration file and restarted JupyterHub. Additional Extras That's it for the main JupyterHub deployment! The next section is about periodic maintenance. After running JupyterHub for two quarters there are a couple lessons learned server regarding maintenance.","title":"Extra Configuration"},{"location":"extra_configuration/#extra-configuration","text":"In this section, we will go over some extra configuration settings we can set in jupyterhub_config.py to help our JupyterHub deployment hum along and help if students forget to logout or too many student try and log in at the same time. Extra Configuration Configuration Options Cull Idle Servers Modify jupyterhub_config.py and upload to server Summary Additional Extras","title":"Extra Configuration"},{"location":"extra_configuration/#configuration-options","text":"In the JupyterHub docs, there is a list of configuration options and descriptions: https://jupyterhub.readthedocs.io/en/stable/api/app.html A couple configuration options in the list seem like good ideas: The class has 24 students, plus one instructor. Given that class size, I think 26 is a good number for the maximum that can use JupyterHub the same time. config c.JupyterHub.active_server_limit = Int(0) # Maximum number of concurrent servers that can be active at a time. Having too many users log in all at the same time can overload the server. Let's set this as 13, so half of the class can log in at the same time. config c.JupyterHub.concurrent_spawn_limit = Int(100) Maximum number of concurrent users that can be spawning at a time. A couple settings relate to shutting down the hub and if user servers shut down too. I want it set so that if I shut down the hub, all the user servers are shut down too. config c.JupyterHub.cleanup_proxy = Bool(True) # Whether to shutdown the proxy when the Hub shuts down. config c.JupyterHub.cleanup_servers = Bool(True) # Whether to shutdown single-user servers when the Hub shuts down.","title":"Configuration Options"},{"location":"extra_configuration/#cull-idle-servers","text":"A problem with the first two JupyterHub deployments was that some students would not shut down their server when they were done working. Then twenty or so servers would all keep running all the time. This script from the JupyterHub Examples repo looks like it might help: https://github.com/jupyterhub/jupyterhub/tree/master/examples/cull-idle To get the cull_idle_servers.py script to run as a JupyterHub service, it looks like you need to add the following to jupyterhub_config.py . (Based on this page in the JupyterHub docs) # /etc/jupyterhub/jupyterhub_config.py import sys ... # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] Put cull_idle_servers.py (found here ) in /etc/jupyterhub/ . Make sure dateutil is intalled in the jupyterhub virtual env. Try >>> import dateutil >>> dateutil.__version__ (using the (jupyterhub) virtual env. Make sure to add import sys to the top of jupyterhub_config.py . Restart JupyterHub. Check for errors. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit If it seems like the cull_idle_servers.py script isn't working, try running cull_idle_servers.py from the command line to see if there are any errors. Make sure you are in the (jupyterhub) virtual environment when you run the script. The script will look for the JUPYTERHUB_API_TOKEN environment variable. An API token can be aquired by logging into JupyterHub (like a regular student) and clicking the [Token] menu from the home page that has the [Stop My Server] and [My Server] buttons. Click [Request new API token] and copy the API token. Then run the lines below (replace ```XXXX```` with your actual API token): $ export JUPYTERHUB_API_TOKEN='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' $ echo $JUPYTERHUB_API_TOKEN # API token is printed $ cd /etc/jupyterhub $ conda activate jupyterhub (jupyterhub)$ python cull_idle_servers.py --timeout=60 --url=http://127.0.0.1:8081/hub/api # check for errors","title":"Cull Idle Servers"},{"location":"extra_configuration/#modify-jupyterhub_configpy-and-upload-to-server","text":"The additions made to jupyterhub_config.py are shown below: # /etc/jupyterhub/jupyterhub_config.py ... ## Extra Configuration # Maximum number of concurrent servers that can be active at a time c.JupyterHub.active_server_limit = 26 # Maximum number of concurrent users that can be spawning at a time c.JupyterHub.concurrent_spawn_limit = 13 # Whether to shutdown the proxy when the Hub shuts down. c.JupyterHub.cleanup_proxy = True # Whether to shutdown single-user servers when the Hub shuts down. c.JupyterHub.cleanup_servers = True # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] ... I made these changes in jupyterhub_config.py locally and then used FileZilla to upload the modified config file to the server. After the modified jupyterhub_config.py file is uploaded to the server, restart JupyterHub and make sure there no errors. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit","title":"Modify jupyterhub_config.py and upload to server"},{"location":"extra_configuration/#summary","text":"In this section we added a few extra configuration options to the jupyterhub_config.py file. A few extra configuration options we included were to limit the number of servers that can run at the same time and limit the amount of servers that can spawn at the same time. We also added a cull_idle_servers.py script to the server which will shut down idle servers if a student has not used them in a while. This involved copying the script locally from GitHub, then uploading the script on the server in the /etc/jupyterhub/ directory. The jupyterhub_config.py file has to be modified so that sys is imported and the cull_idle_servers.py script runs and a JupyterHub service Finally we uploaded the modified jupyterhubconfig.py configuration file and restarted JupyterHub.","title":"Summary"},{"location":"extra_configuration/#additional-extras","text":"That's it for the main JupyterHub deployment! The next section is about periodic maintenance. After running JupyterHub for two quarters there are a couple lessons learned server regarding maintenance.","title":"Additional Extras"},{"location":"github_extension/","text":"GitHub Extension It is possible put in a \"GitHub\" tab into each user's JupyterLab browser. When students click on the GitHub tab, they can view any repo on GitHub.com. Since the \"labs\" and \"notes\" for the course are saved on GitHub, a directory with pre-constructed lab assignments and notes (saved on GitHub) can be pulled in for each JupyterHub user. Any public GitHub repo can be shown and accessed in JupyterLab using the GitHub tab once the GitHub extension for JupyterLab is installed. GitHub Extension Install nodejs Install GitHub extension for JupyterLab Restart JupyterHub and test it out Create notebook config file Acquire GitHub token Modify notebook config file pip install GitHub server extension Point JupyterHub to notebook config file Restart JupyterHub Summary Install nodejs To install the GitHub extension for JupyterHub, first log into the server and install nodejs with conda into the (jupyterhub) virtual environment. $ sudo systemctl stop jupyterhub $ conda activate jupyterhub (jupyterhub)$ conda install -c conda-forge nodejs Install GitHub extension for JupyterLab Enter another conda install line to install the GitHub extension for JupyterLab. (jupyterhub)$ jupyter labextension install @jupyterlab/github Restart JupyterHub and test it out $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit Create notebook config file In order for the GitHub tab in JupyterLab to arrive at a specific repo, a couple configuration steps are required. First a notebook config file needs to be created. This notebook config file is different than the jupypterhub_config.py file we have been modifying during this JupyterHub deployment. Acquire GitHub token The docs for the GitHub extension for JupyterLab note that a GitHub token should be acquired, otherwise there is a small limit to the number of requests that can be made to GitHub when the GitHub Tab in JupyterLab is used. Modify notebook config file In the notebook config file (not the jupyterhub_config.py file): c.GitHubConfig.api_url = 'https://git.myserver.com/api/v3' pip install GitHub server extension Point JupyterHub to notebook config file Restart JupyterHub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]+[c] to exit Summary This docs page provided an overview of the GitHub extension for JupyterLab. The GitHub extension for JupyterLab adds a new tab in the JupyterLab interface that students can open and see what files are saved to a particular GitHub repo. The GitHub extension for JupyterLab first needs to be installed. After it is installed, there are some extra configuration steps to cause a specific repo to be the default repo when JupyterHub launches students into the JupyterLab interface and they select the GitHub tab.","title":"GitHub Extension for JupyterLab"},{"location":"github_extension/#github-extension","text":"It is possible put in a \"GitHub\" tab into each user's JupyterLab browser. When students click on the GitHub tab, they can view any repo on GitHub.com. Since the \"labs\" and \"notes\" for the course are saved on GitHub, a directory with pre-constructed lab assignments and notes (saved on GitHub) can be pulled in for each JupyterHub user. Any public GitHub repo can be shown and accessed in JupyterLab using the GitHub tab once the GitHub extension for JupyterLab is installed. GitHub Extension Install nodejs Install GitHub extension for JupyterLab Restart JupyterHub and test it out Create notebook config file Acquire GitHub token Modify notebook config file pip install GitHub server extension Point JupyterHub to notebook config file Restart JupyterHub Summary","title":"GitHub Extension"},{"location":"github_extension/#install-nodejs","text":"To install the GitHub extension for JupyterHub, first log into the server and install nodejs with conda into the (jupyterhub) virtual environment. $ sudo systemctl stop jupyterhub $ conda activate jupyterhub (jupyterhub)$ conda install -c conda-forge nodejs","title":"Install nodejs"},{"location":"github_extension/#install-github-extension-for-jupyterlab","text":"Enter another conda install line to install the GitHub extension for JupyterLab. (jupyterhub)$ jupyter labextension install @jupyterlab/github","title":"Install GitHub extension for JupyterLab"},{"location":"github_extension/#restart-jupyterhub-and-test-it-out","text":"$ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit","title":"Restart JupyterHub and test it out"},{"location":"github_extension/#create-notebook-config-file","text":"In order for the GitHub tab in JupyterLab to arrive at a specific repo, a couple configuration steps are required. First a notebook config file needs to be created. This notebook config file is different than the jupypterhub_config.py file we have been modifying during this JupyterHub deployment.","title":"Create notebook config file"},{"location":"github_extension/#acquire-github-token","text":"The docs for the GitHub extension for JupyterLab note that a GitHub token should be acquired, otherwise there is a small limit to the number of requests that can be made to GitHub when the GitHub Tab in JupyterLab is used.","title":"Acquire GitHub token"},{"location":"github_extension/#modify-notebook-config-file","text":"In the notebook config file (not the jupyterhub_config.py file): c.GitHubConfig.api_url = 'https://git.myserver.com/api/v3'","title":"Modify notebook config file"},{"location":"github_extension/#pip-install-github-server-extension","text":"","title":"pip install GitHub server extension"},{"location":"github_extension/#point-jupyterhub-to-notebook-config-file","text":"","title":"Point JupyterHub to notebook config file"},{"location":"github_extension/#restart-jupyterhub","text":"$ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]+[c] to exit","title":"Restart JupyterHub"},{"location":"github_extension/#summary","text":"This docs page provided an overview of the GitHub extension for JupyterLab. The GitHub extension for JupyterLab adds a new tab in the JupyterLab interface that students can open and see what files are saved to a particular GitHub repo. The GitHub extension for JupyterLab first needs to be installed. After it is installed, there are some extra configuration steps to cause a specific repo to be the default repo when JupyterHub launches students into the JupyterLab interface and they select the GitHub tab.","title":"Summary"},{"location":"google_oauth/","text":"Google Authentication Now that the JupyterHub deployment works and we have two users set up on the server, we are going to get into the weeds of getting the Google authenticator to work. Why Google authenticator instead of just setting up users one by one at the command line? Our college uses the Gmail suite for both staff and students. When students log onto their college email, they are logging into Gmail. Students can use Google calendar and Google drive with their college email account as well. Instead of emailing students individual user names and passwords (and having students remember another set of usernames and passwords), students could log into JuypterHub using the same Google login that they use to access their college email, Google drive and calendar. It's just going to take a bit of work to get there. Google Authentication Google OAuth Instance Pull out the client ID and client secret from the downloaded json file Add the json file to .gitignore Move the json file to the server Modify jupyterhub_config.py Install oauthenticator, restart JupyterHub and login Log in with a Google username and password Summary Next Steps Google OAuth Instance To allow students to use Google usernames and passwords to log into JupyterHub, the first thing we need to do is set up a Google OAuth instance. I set up the Google OAuth instance using my personal Gmail account, rather than my college Gmail account. Some parts of Google suite are not available in my college profile, like YouTube and developer tabs. To obtain the Google OAuth credentials, we need to log into the Google API console https://console.developers.google.com/ and select [Credentials] on the lefthand menu. Next we'll create a new OAuth credential under [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID]: To create a set of Google OAuth credentials we need to input: Authorized JavaScript origins: https://mydomain.org Authorized redirect URIs: https://mydomain.org/hub/oauth_callback After clicking [Create] a problem surfaced. The Google OAuth dashboard noted that: Invalid Origin: domain must be added to the authorized domains list before submitting So click the [authorized domains list] link and enter the domain name for the JupyterHub server in the text box under [Authorized domains]. Then click [Submit for verification] and [Save]. For some reason the authorize domains submit for verification step and save step took a couple tries and more than a couple minutes. I don't know if Google is going a DNS lookup or what kind of verification steps they do - either way it took some time for the domain to be \"verified\". Once the domain is verified, go back to the [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID] screen and try entering in the [Authorized JavaScript origins] and [Authorized redirect URIs] again. The scary red [Invalid Origin] should be absent as long as the domain has been verified. After creating a new set of Google OAuth credentials, note the: client ID client secret The client ID and client secret strings will be included in our revised JupyterHub configuration. Pull out the client ID and client secret from the downloaded json file For this JupyterHub Deployment, I also downloaded the json file that contains the client ID and client secret from Google's OAuth dashboard. You can access the json file containing the client ID and client secret by clicking the [Credentials] tab and find the credential you just created. On the right hand side is a download icon. Clicking this icon downloads a json file that contains our client ID and client secret. After the json file downloads, you can open the json file in a web browser or a code editor. It has a structure that looks like this: {\"web\": {\"client_id\":\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.apps.googleusercontent.com\", \"project_id\":\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\", \"token_uri\":\"https://oauth2.googleapis.com/token\", \"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\", \"client_secret\":\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"redirect_uris\":[\"https:XXXXXXXXXXXXXXX/hub/oauth_callback\"], \"javascript_origins\":[\"https://eXXXXXXXXXXXX.org\"] } } On a local computer, rename the json file to google_oauth_credentials.json . We can use Python and the json module from the Standard Library to pull out the \"client_id\" and \"client_secret\" from the json file. Make sure the json file is in the same directory on your local computer where the Python code is run. Try the following Python code on your local computer: with open('google_oauth_credentials.json') as f: google_oauth = json.load(f) print(google_oauth['web']['client_id']) print(google_oauth['web']['client_secret'] The output will be the 'client_id' and 'client_secret' from the json file. Add the json file to .gitignore Now we need to move the google_oauth_credentials.json to the sever, but before we do: MAKE SURE TO ADD THE FILE TO .gitignore !!! WE DON'T WANT PRIVATE CREDENTIALS STORED ON GITHUB !!! . Warning Important! Do not save private credentials in a public GitHub repository! Keep your credentials private! In .gitignore on my local machine, I added the following lines at the end. Note that locally this file is saved at projectroot/etc/jupyterhub/google_oauth_credentials.json # .gitignore ... ## Config files /etc/jupyterhub/config.json /etc/jupyterhub/google_oauth_credentials.json ... Move the json file to the server Now move the json file over to the server and save it in the /etc/jupyterhub/ directory. I used FileZilla to move the json file over to the server instead of using copy-paste into PuTTY and the nano code editor. Open FileZilla and select [File] \u2192 [Site Manager... ]. Enter in the server's IP address and select the SSH key used to log into the server. Make sure to select: [Protocol:] SFTP - SSH File Transfer Protocol [Host:] IP address of server [Port]: 22 [Logon Type:] Key file [User:] peter (or your non-root sudo user on the server) [Key file:] [Browse...] and find the SSH key used to log onto the server Click [Connect] to connect to the server with FileZilla. Move both file browsers to /etc/jupyterhub . On the local computer, the json file is present. On the server, only the jupyterhub config file is present. Drag the json file over to the server side of the window. Now that the json file is saved on the server, you can the FileZilla window. After the json file is saved on the server, the contents of /etc/jupyterhub on the server should be: /etc/jupyterhub/ \u251c\u2500\u2500 google_oauth_credentials.json \u2514\u2500\u2500 jupyterhub_config.py Modify jupyterhub_config.py Once we get our Google OAuth credentials, we need to edit jupyterhub_conf.py again. Note your Google OAuth credentials are replaced by the credentials from the google_oauth_credentials.json file. I did the edits to the jupyterhub_config.py file locally in a code editor. There is a lot of places to miss type or miss copy and paste. You can move the revised jupyterhub_config.py file over to the server with FileZilla, just like we moved the json file. # /etc/jupyterhub/jupyterhub_config.py # used to read the json google oauth config file import json # For Google OAuth from oauthenticator.google import LocalGoogleOAuthenticator c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhub/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # Google OAuth Login c.JupyterHub.authenticator_class = LocalGoogleOAuthenticator with open('/etc/jupyterhub/google_oauth_credentials.json') as f: google_oauth = json.load(f) c.LocalGoogleOAuthenticator.client_id = google_oauth['web']['client_id'] c.LocalGoogleOAuthenticator.client_secret = google_oauth['web']['client_secret'] c.LocalGoogleOAuthenticator.oauth_callback_url = 'https://engr101lab.org/hub/oauth_callback' # replace with your domain c.LocalGoogleOAuthenticator.create_system_users = True c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] c.LocalGoogleOAuthenticator.hosted_domain = 'pcc.edu' # replace with collegedomain.edu c.LocalGoogleOAuthenticator.login_service = 'Portland Community College' # replace with 'College Name' # Users #c.Authenticator.whitelist = {'peter','gabby'} c.Authenticator.admin_users = {'peter','peter.kazarinoff'} This little line: c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] was a real gottacha. Our college email addresses are in the form: firstname.lastname@college.edu When a student logs in, JupyterHub tries to create a new Linux user with a dot . in their username. Usernames with . doesn't work on Linux. I tried to create a new Linux user with a dot in their username, and the terminal asked me to use the --force-badname flag. So --force-badname is what we'll add to the c.Authenticator.add_user_cmd list. Otherwise, users (students) will be able to authenticate with Google, but they won't get a new user account on the server, and they won't be able to run notebooks or Python code. Install oauthenticator, restart JupyterHub and login Before we can restart JupyterHub and try our Google OAuth configuration out, we need to install the Python package oauthenticator into the virtual environment that runs JupyterHub. Log onto the server, activate the virtual environment, and install oauthenticator with pip ( oauthenticator is not in any conda channels). $ conda activate jupyterhub (jupyterhub)$ pip install oauthenticator (jupyterhub)$ python >>> import oauthenticator >>> oauthenticator.__version__ '0.8.0' >>> exit() (jupyterhub)$ conda deactivate $ Restart JupyterHub and browse to the web address attached to the server. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub You should see Active in the status screen. If not, there is some trouble shooting to do. Use [Ctrl]+[c] to exit the status screen. \u25cf jupyterhub.service - JupyterHub Loaded: loaded (/etc/systemd/system/jupyterhub.service; disabled; vendor preset: enabled) Active: active (running) since Fri 2019-02-08 18:42:23 UTC; 6s ago Main PID: 9178 (jupyterhub) Tasks: 8 (limit: 1152) Log in with a Google username and password If JupyterHub is running OK and there were no errors after the revisions to the jupyterhub_config.py file. Open a web browser and try to Log in. The login window should now look something like: We can log in with our Google user name and password (college username and password). Pretty sweet! Note the Jupyter notebook file browser is empty after we log on. A new user was created by JupyterHub when we logged in. This new user's home directory is empty. If you added your college username was added to the c.Authenticator.admin_users = { } set in jupyterhub_config.py , you will be able to see an [Admin] tab when you click [Control Panel] in the Jupyter notebook file browser. If you click [Admin], you should see three users in the user list. You can shut down the you college username's notebook server and logout (or play around with some notebooks). After we log in using our college username and password, we can see if JupyterHub created a new user (with our college username) on the server. The command below produces a long list of users. This long list contains the non-root sudo user peter and the Google authenticated user (college username). $ awk -F':' '{ print $1}' /etc/passwd .... uuidd dnsmasq landscape sshd pollinate peter gabby peter.kazarinoff Summary This was a big section and we got a lot accomplished. At the end of it, we have a running JupyterHub server that allows students and faculty to log into JupyterHub using their college useranmes and passwords. We accomplished this in a couple steps: Create a Google OAuth instance in the Google Developer's console. Download and save the json file that stores the client ID and client secret. Figure out how to pull the client ID and secret out of the json file using Python's json module from the Standard Library. Add the json file to .gitignore so that our private client ID and private client secret are not made public. Move the json file over to the server with FileZilla. Modify the jupyterhub_config.py file. Add Google authentication to our JupyterHub configuration. On the server, pip install oauthenticator into the virtual environment that runs JupyterHub. Restart JupyterHub and login with a Google username and password. Use the JuputerHub admin and the terminal to see the new user JupyterHub added to our server Next Steps The next step is to make the login screen look like our college login screen. Right now, students see a orange button on the login screen. Next, we'll mess around with some templates, html and css to get our JupyterHub login screen to look a lot more like the college login screen.","title":"Google OAuth"},{"location":"google_oauth/#google-authentication","text":"Now that the JupyterHub deployment works and we have two users set up on the server, we are going to get into the weeds of getting the Google authenticator to work. Why Google authenticator instead of just setting up users one by one at the command line? Our college uses the Gmail suite for both staff and students. When students log onto their college email, they are logging into Gmail. Students can use Google calendar and Google drive with their college email account as well. Instead of emailing students individual user names and passwords (and having students remember another set of usernames and passwords), students could log into JuypterHub using the same Google login that they use to access their college email, Google drive and calendar. It's just going to take a bit of work to get there. Google Authentication Google OAuth Instance Pull out the client ID and client secret from the downloaded json file Add the json file to .gitignore Move the json file to the server Modify jupyterhub_config.py Install oauthenticator, restart JupyterHub and login Log in with a Google username and password Summary Next Steps","title":"Google Authentication"},{"location":"google_oauth/#google-oauth-instance","text":"To allow students to use Google usernames and passwords to log into JupyterHub, the first thing we need to do is set up a Google OAuth instance. I set up the Google OAuth instance using my personal Gmail account, rather than my college Gmail account. Some parts of Google suite are not available in my college profile, like YouTube and developer tabs. To obtain the Google OAuth credentials, we need to log into the Google API console https://console.developers.google.com/ and select [Credentials] on the lefthand menu. Next we'll create a new OAuth credential under [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID]: To create a set of Google OAuth credentials we need to input: Authorized JavaScript origins: https://mydomain.org Authorized redirect URIs: https://mydomain.org/hub/oauth_callback After clicking [Create] a problem surfaced. The Google OAuth dashboard noted that: Invalid Origin: domain must be added to the authorized domains list before submitting So click the [authorized domains list] link and enter the domain name for the JupyterHub server in the text box under [Authorized domains]. Then click [Submit for verification] and [Save]. For some reason the authorize domains submit for verification step and save step took a couple tries and more than a couple minutes. I don't know if Google is going a DNS lookup or what kind of verification steps they do - either way it took some time for the domain to be \"verified\". Once the domain is verified, go back to the [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID] screen and try entering in the [Authorized JavaScript origins] and [Authorized redirect URIs] again. The scary red [Invalid Origin] should be absent as long as the domain has been verified. After creating a new set of Google OAuth credentials, note the: client ID client secret The client ID and client secret strings will be included in our revised JupyterHub configuration.","title":"Google OAuth Instance"},{"location":"google_oauth/#pull-out-the-client-id-and-client-secret-from-the-downloaded-json-file","text":"For this JupyterHub Deployment, I also downloaded the json file that contains the client ID and client secret from Google's OAuth dashboard. You can access the json file containing the client ID and client secret by clicking the [Credentials] tab and find the credential you just created. On the right hand side is a download icon. Clicking this icon downloads a json file that contains our client ID and client secret. After the json file downloads, you can open the json file in a web browser or a code editor. It has a structure that looks like this: {\"web\": {\"client_id\":\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.apps.googleusercontent.com\", \"project_id\":\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\", \"token_uri\":\"https://oauth2.googleapis.com/token\", \"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\", \"client_secret\":\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"redirect_uris\":[\"https:XXXXXXXXXXXXXXX/hub/oauth_callback\"], \"javascript_origins\":[\"https://eXXXXXXXXXXXX.org\"] } } On a local computer, rename the json file to google_oauth_credentials.json . We can use Python and the json module from the Standard Library to pull out the \"client_id\" and \"client_secret\" from the json file. Make sure the json file is in the same directory on your local computer where the Python code is run. Try the following Python code on your local computer: with open('google_oauth_credentials.json') as f: google_oauth = json.load(f) print(google_oauth['web']['client_id']) print(google_oauth['web']['client_secret'] The output will be the 'client_id' and 'client_secret' from the json file.","title":"Pull out the client ID and client secret from the downloaded json file"},{"location":"google_oauth/#add-the-json-file-to-gitignore","text":"Now we need to move the google_oauth_credentials.json to the sever, but before we do: MAKE SURE TO ADD THE FILE TO .gitignore !!! WE DON'T WANT PRIVATE CREDENTIALS STORED ON GITHUB !!! . Warning Important! Do not save private credentials in a public GitHub repository! Keep your credentials private! In .gitignore on my local machine, I added the following lines at the end. Note that locally this file is saved at projectroot/etc/jupyterhub/google_oauth_credentials.json # .gitignore ... ## Config files /etc/jupyterhub/config.json /etc/jupyterhub/google_oauth_credentials.json ...","title":"Add the json file to .gitignore"},{"location":"google_oauth/#move-the-json-file-to-the-server","text":"Now move the json file over to the server and save it in the /etc/jupyterhub/ directory. I used FileZilla to move the json file over to the server instead of using copy-paste into PuTTY and the nano code editor. Open FileZilla and select [File] \u2192 [Site Manager... ]. Enter in the server's IP address and select the SSH key used to log into the server. Make sure to select: [Protocol:] SFTP - SSH File Transfer Protocol [Host:] IP address of server [Port]: 22 [Logon Type:] Key file [User:] peter (or your non-root sudo user on the server) [Key file:] [Browse...] and find the SSH key used to log onto the server Click [Connect] to connect to the server with FileZilla. Move both file browsers to /etc/jupyterhub . On the local computer, the json file is present. On the server, only the jupyterhub config file is present. Drag the json file over to the server side of the window. Now that the json file is saved on the server, you can the FileZilla window. After the json file is saved on the server, the contents of /etc/jupyterhub on the server should be: /etc/jupyterhub/ \u251c\u2500\u2500 google_oauth_credentials.json \u2514\u2500\u2500 jupyterhub_config.py","title":"Move the json file to the server"},{"location":"google_oauth/#modify-jupyterhub_configpy","text":"Once we get our Google OAuth credentials, we need to edit jupyterhub_conf.py again. Note your Google OAuth credentials are replaced by the credentials from the google_oauth_credentials.json file. I did the edits to the jupyterhub_config.py file locally in a code editor. There is a lot of places to miss type or miss copy and paste. You can move the revised jupyterhub_config.py file over to the server with FileZilla, just like we moved the json file. # /etc/jupyterhub/jupyterhub_config.py # used to read the json google oauth config file import json # For Google OAuth from oauthenticator.google import LocalGoogleOAuthenticator c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhub/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # Google OAuth Login c.JupyterHub.authenticator_class = LocalGoogleOAuthenticator with open('/etc/jupyterhub/google_oauth_credentials.json') as f: google_oauth = json.load(f) c.LocalGoogleOAuthenticator.client_id = google_oauth['web']['client_id'] c.LocalGoogleOAuthenticator.client_secret = google_oauth['web']['client_secret'] c.LocalGoogleOAuthenticator.oauth_callback_url = 'https://engr101lab.org/hub/oauth_callback' # replace with your domain c.LocalGoogleOAuthenticator.create_system_users = True c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] c.LocalGoogleOAuthenticator.hosted_domain = 'pcc.edu' # replace with collegedomain.edu c.LocalGoogleOAuthenticator.login_service = 'Portland Community College' # replace with 'College Name' # Users #c.Authenticator.whitelist = {'peter','gabby'} c.Authenticator.admin_users = {'peter','peter.kazarinoff'} This little line: c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] was a real gottacha. Our college email addresses are in the form: firstname.lastname@college.edu When a student logs in, JupyterHub tries to create a new Linux user with a dot . in their username. Usernames with . doesn't work on Linux. I tried to create a new Linux user with a dot in their username, and the terminal asked me to use the --force-badname flag. So --force-badname is what we'll add to the c.Authenticator.add_user_cmd list. Otherwise, users (students) will be able to authenticate with Google, but they won't get a new user account on the server, and they won't be able to run notebooks or Python code.","title":"Modify jupyterhub_config.py"},{"location":"google_oauth/#install-oauthenticator-restart-jupyterhub-and-login","text":"Before we can restart JupyterHub and try our Google OAuth configuration out, we need to install the Python package oauthenticator into the virtual environment that runs JupyterHub. Log onto the server, activate the virtual environment, and install oauthenticator with pip ( oauthenticator is not in any conda channels). $ conda activate jupyterhub (jupyterhub)$ pip install oauthenticator (jupyterhub)$ python >>> import oauthenticator >>> oauthenticator.__version__ '0.8.0' >>> exit() (jupyterhub)$ conda deactivate $ Restart JupyterHub and browse to the web address attached to the server. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub You should see Active in the status screen. If not, there is some trouble shooting to do. Use [Ctrl]+[c] to exit the status screen. \u25cf jupyterhub.service - JupyterHub Loaded: loaded (/etc/systemd/system/jupyterhub.service; disabled; vendor preset: enabled) Active: active (running) since Fri 2019-02-08 18:42:23 UTC; 6s ago Main PID: 9178 (jupyterhub) Tasks: 8 (limit: 1152)","title":"Install oauthenticator, restart JupyterHub and login"},{"location":"google_oauth/#log-in-with-a-google-username-and-password","text":"If JupyterHub is running OK and there were no errors after the revisions to the jupyterhub_config.py file. Open a web browser and try to Log in. The login window should now look something like: We can log in with our Google user name and password (college username and password). Pretty sweet! Note the Jupyter notebook file browser is empty after we log on. A new user was created by JupyterHub when we logged in. This new user's home directory is empty. If you added your college username was added to the c.Authenticator.admin_users = { } set in jupyterhub_config.py , you will be able to see an [Admin] tab when you click [Control Panel] in the Jupyter notebook file browser. If you click [Admin], you should see three users in the user list. You can shut down the you college username's notebook server and logout (or play around with some notebooks). After we log in using our college username and password, we can see if JupyterHub created a new user (with our college username) on the server. The command below produces a long list of users. This long list contains the non-root sudo user peter and the Google authenticated user (college username). $ awk -F':' '{ print $1}' /etc/passwd .... uuidd dnsmasq landscape sshd pollinate peter gabby peter.kazarinoff","title":"Log in with a Google username and password"},{"location":"google_oauth/#summary","text":"This was a big section and we got a lot accomplished. At the end of it, we have a running JupyterHub server that allows students and faculty to log into JupyterHub using their college useranmes and passwords. We accomplished this in a couple steps: Create a Google OAuth instance in the Google Developer's console. Download and save the json file that stores the client ID and client secret. Figure out how to pull the client ID and secret out of the json file using Python's json module from the Standard Library. Add the json file to .gitignore so that our private client ID and private client secret are not made public. Move the json file over to the server with FileZilla. Modify the jupyterhub_config.py file. Add Google authentication to our JupyterHub configuration. On the server, pip install oauthenticator into the virtual environment that runs JupyterHub. Restart JupyterHub and login with a Google username and password. Use the JuputerHub admin and the terminal to see the new user JupyterHub added to our server","title":"Summary"},{"location":"google_oauth/#next-steps","text":"The next step is to make the login screen look like our college login screen. Right now, students see a orange button on the login screen. Next, we'll mess around with some templates, html and css to get our JupyterHub login screen to look a lot more like the college login screen.","title":"Next Steps"},{"location":"install_jupyterhub/","text":"Install JupyterHub After the server is set up, and a non-root sudo user has been created, it is time to install JupyterHub on the server. Install JupyterHub Update System Install Miniconda Change Miniconda3 Permissions Create a virtual environment and install and packages Run a very unsecured instance of Jupyter Hub just to see if it works Quick! Log out and shut down JupyterHub Summary Next Steps Update System It is probably best to update the packages installed on the server in case there are updates to the operating system and installed packages since the server was created. Open PuTTY and log into the server as the non-root sudo user we created in the last step. Then update the system: $ sudo apt-get update $ sudo apt-get upgrade Install Miniconda Before we install JupyterHub on the server, we need to install Python and create a virtual environment. We'll install Python using Miniconda and then use the conda package manager to create the virtual environment and install Python packages and JupyterHub. Miniconda is a lightweight version of Anaconda . Miniconda only comes with Python and the conda package manager. All of the Python packages that come with Anaconda are left out of Miniconda . This is just fine for us, since we are going to create a virtual environment anyway and don't need all of the packages that come with Anaconda in our JupyterHub deployment. For this JupyterHub deployment, we'll install Miniconda in the /opt directory. The Miniconda install is lighter than the full Anaconda install, and we don't need all the packages and GUI applications that Anaconda provides. The packages that we need in this deployment of JupyterHub, we can install in a separate virtual environment. I followed this tutorial from Digital Ocean. Go to https://repo.continuum.io/archive/ and look down the list of installs for the newest installer that corresponds to: Miniconda3 (not Miniconda2, we don't want legacy Python version 2.7) Linux x86 64 (bit) .sh (linux shell script) The URL of the latest Miniconda install for Linux will look something like: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh To downland and install Miniconda on the server, we'll use the curl command and run the bash installer from the command line: $ cd /tmp $ curl -O $ https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh $ sudo bash Miniconda3-latest-Linux-x86_64.sh During the Miniconda install, accept the licence. Then specify the following installation directory. This step ensures that Miniconda is installed in the /opt directory, which is where the JupyterHub docs specify user programs should reside. /opt/miniconda3/ During the installation, the installer script will ask: Do you wish the installer to initialize Miniconda3 in your /home/peter/.bashrc ? [yes|no] [no] >>> yes Type yes . We want to be able to run conda from the command line. So make sure to allow Miniconda to append your PATH during the installation. After installation, we need to reload the .bashrc file because Miniconda made changes to our .bashrc during the install (when it added conda to our PATH). $ cd ~ $ source .bashrc When the install is complete, look in /opt , and see the miniconda3 directory. $ cd /opt $ ls miniconda3 Change Miniconda3 Permissions Now we need to deal with some permission issues. Since I am running as the user peter on the Digital Ocean server, I need to make sure the user peter has read, write, and execute permissions on the entire /opt/miniconda3/ directory. We can give peter user permissions with chmod and chown . $ cd /opt $ ls miniconda3 $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxr-xr-x 13 root root 4096 Oct 30 04:47 miniconda3 Currently, the owner of the miniconda3 directory is root and the group is root . The owner root has read, write, execute privileges ( rwx ) and the group root has read, execute privileges ( r-x ), but no write privileges. Let's modify the read, write, execute privileges so that the group root can read, write, and execute ( rwx ). $ sudo chmod -R g+w miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root root 4096 Oct 30 04:47 miniconda3 OK, now let's change the group corresponding to the miniconda3/ directory from root to peter . $ sudo chown -R root:peter miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root peter 4096 Oct 30 04:47 miniconda3 Now the user peter will be able to install packages using conda and pip in the Miniconda3 installation in the /opt directory. Now that the permissions are changed, we should be able to run conda from the command line. Try: $ conda --version If you see output, that means Miniconda was installed and conda can be run by the non-root user. Create a virtual environment and install and packages For this JupyterHub install, we are going to create a conda environment (a virtual environment) and install packages into that environment. We'll call the conda environment jupyterhub and use python=3.7 as our Python version. Then activate the jupyterhub environment and install NumPy , Matplotlib , Pandas and Jupyter . Also don't forget to install xlrd , this package is needed for Pandas to read .xlsx files. Finally, install JupyterLab and JupyterHub from the conda-forge channel. $ conda create -n jupyterhub python=3.7 $ conda activate jupyterhub $(jupyterhub) conda install numpy matplotlib pandas xlrd jupyter notebook $(jupyterhub) conda install -c conda-forge jupyterlab $(jupyterhub) conda install -c conda-forge jupyterhub Run a very unsecured instance of Jupyter Hub just to see if it works OK- let's give JupyterHub a whirl. We'll start JupterHub for the first time. Note the --no-ssl flag at the end of the command. This flag needs to be included or you won't be able to browse to the server. Also note we have to have our (jupyterhub) virtual environment active when we run the command. $(jupyterhub) jupyterhub --no-ssl We see some output in the PuTTY window. The last line is something like JupyterHub is now running at http://:8000/ . The first time I set up JupyterHub, I wasn't able to see the site using a web browser. No web page loaded, and the connection timed out. Why? It turns out Digital Ocean installs a firewall called ufw by default and turns the ufw firewall on. When the server was created, ufw was configured to only allow incoming connections on ports 22, 80 and 433. The output below is shown when we first log into the Digital Ocean server: \"ufw\" has been enabled. All ports except 22 (SSH), 80 (http) and 443 (https) have been blocked by default. But JupyterHub runs on port 8000 - it tells us so when JupyterHub starts. So we need to configure ufw to allow connections on port 8000 (at least for now, just to see if JupyterHub works). To allow communication on port 8000 and start JupyterHub, type: $(jupyterhub) sudo ufw allow 8000 # make sure the (jupyterhub) conda env is activated $(jupyterhub) jupyterhub --no-ssl Now we can browse to the server IP address of our Digital Ocean Droplet appended with :8000 . The web address should look something like: http://165.228.68.178:8000 . You can find the IP address of the server by going into the Digital Ocean dashboard. The JupyterHub login screen looks like: Awesome! Quick log into JupyterHub using the username and password for the non-root sudo user (in my case peter ) that we set up earlier and are running as in our current PuTTY session. You should see the typical notebook file browser with all the files you can see when you run ls ~/ . Try creating and running a new Jupyter notebook. The notebook works just like a Jupyter notebook running locally . Quick! Log out and shut down JupyterHub Warning Warning! You should not run JupyterHub without SSL encryption on a public network. Quick! Log out and shut down JupyterHub . (does quick really matter in internet security?) The site is running without any ssl security over regular HTTP not HTTPS. Key in [Ctrl] + [c] to stop JupyterHub. After you have confirmed that JupyterHub works, close off Port 8000 on the server by keying in the following command. $(jupyterhub) sudo ufw deny 8000 $(jupyterhub) sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 DENY Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) DENY Anywhere (v6) Summary In this section, we installed Miniconda onto the server. We made sure Miniconda was installed in the /opt directory and then changed the directory permissions so that our non-root sudo user can use the Miniconda installation. Next we created a Python 3.7 virtual environment and installed NumPy, Matplotlib, Pandas, xlrd, and Jupyter into it. Then we installed JupyterLab and JupyterHub into the virtual environment from the conda-forge channel. Finally we ran a very un-secure instance of JupyterHub with no SSL encryption. Running JupyterHub without SSL encryption is NOT ADVISED . Next Steps The next step is to acquire a domain name and link the domain name to our Digital Ocean server.","title":"Install JupyterHub"},{"location":"install_jupyterhub/#install-jupyterhub","text":"After the server is set up, and a non-root sudo user has been created, it is time to install JupyterHub on the server. Install JupyterHub Update System Install Miniconda Change Miniconda3 Permissions Create a virtual environment and install and packages Run a very unsecured instance of Jupyter Hub just to see if it works Quick! Log out and shut down JupyterHub Summary Next Steps","title":"Install JupyterHub"},{"location":"install_jupyterhub/#update-system","text":"It is probably best to update the packages installed on the server in case there are updates to the operating system and installed packages since the server was created. Open PuTTY and log into the server as the non-root sudo user we created in the last step. Then update the system: $ sudo apt-get update $ sudo apt-get upgrade","title":"Update System"},{"location":"install_jupyterhub/#install-miniconda","text":"Before we install JupyterHub on the server, we need to install Python and create a virtual environment. We'll install Python using Miniconda and then use the conda package manager to create the virtual environment and install Python packages and JupyterHub. Miniconda is a lightweight version of Anaconda . Miniconda only comes with Python and the conda package manager. All of the Python packages that come with Anaconda are left out of Miniconda . This is just fine for us, since we are going to create a virtual environment anyway and don't need all of the packages that come with Anaconda in our JupyterHub deployment. For this JupyterHub deployment, we'll install Miniconda in the /opt directory. The Miniconda install is lighter than the full Anaconda install, and we don't need all the packages and GUI applications that Anaconda provides. The packages that we need in this deployment of JupyterHub, we can install in a separate virtual environment. I followed this tutorial from Digital Ocean. Go to https://repo.continuum.io/archive/ and look down the list of installs for the newest installer that corresponds to: Miniconda3 (not Miniconda2, we don't want legacy Python version 2.7) Linux x86 64 (bit) .sh (linux shell script) The URL of the latest Miniconda install for Linux will look something like: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh To downland and install Miniconda on the server, we'll use the curl command and run the bash installer from the command line: $ cd /tmp $ curl -O $ https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh $ sudo bash Miniconda3-latest-Linux-x86_64.sh During the Miniconda install, accept the licence. Then specify the following installation directory. This step ensures that Miniconda is installed in the /opt directory, which is where the JupyterHub docs specify user programs should reside. /opt/miniconda3/ During the installation, the installer script will ask: Do you wish the installer to initialize Miniconda3 in your /home/peter/.bashrc ? [yes|no] [no] >>> yes Type yes . We want to be able to run conda from the command line. So make sure to allow Miniconda to append your PATH during the installation. After installation, we need to reload the .bashrc file because Miniconda made changes to our .bashrc during the install (when it added conda to our PATH). $ cd ~ $ source .bashrc When the install is complete, look in /opt , and see the miniconda3 directory. $ cd /opt $ ls miniconda3","title":"Install Miniconda"},{"location":"install_jupyterhub/#change-miniconda3-permissions","text":"Now we need to deal with some permission issues. Since I am running as the user peter on the Digital Ocean server, I need to make sure the user peter has read, write, and execute permissions on the entire /opt/miniconda3/ directory. We can give peter user permissions with chmod and chown . $ cd /opt $ ls miniconda3 $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxr-xr-x 13 root root 4096 Oct 30 04:47 miniconda3 Currently, the owner of the miniconda3 directory is root and the group is root . The owner root has read, write, execute privileges ( rwx ) and the group root has read, execute privileges ( r-x ), but no write privileges. Let's modify the read, write, execute privileges so that the group root can read, write, and execute ( rwx ). $ sudo chmod -R g+w miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root root 4096 Oct 30 04:47 miniconda3 OK, now let's change the group corresponding to the miniconda3/ directory from root to peter . $ sudo chown -R root:peter miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root peter 4096 Oct 30 04:47 miniconda3 Now the user peter will be able to install packages using conda and pip in the Miniconda3 installation in the /opt directory. Now that the permissions are changed, we should be able to run conda from the command line. Try: $ conda --version If you see output, that means Miniconda was installed and conda can be run by the non-root user.","title":"Change Miniconda3 Permissions"},{"location":"install_jupyterhub/#create-a-virtual-environment-and-install-and-packages","text":"For this JupyterHub install, we are going to create a conda environment (a virtual environment) and install packages into that environment. We'll call the conda environment jupyterhub and use python=3.7 as our Python version. Then activate the jupyterhub environment and install NumPy , Matplotlib , Pandas and Jupyter . Also don't forget to install xlrd , this package is needed for Pandas to read .xlsx files. Finally, install JupyterLab and JupyterHub from the conda-forge channel. $ conda create -n jupyterhub python=3.7 $ conda activate jupyterhub $(jupyterhub) conda install numpy matplotlib pandas xlrd jupyter notebook $(jupyterhub) conda install -c conda-forge jupyterlab $(jupyterhub) conda install -c conda-forge jupyterhub","title":"Create a virtual environment and install and packages"},{"location":"install_jupyterhub/#run-a-very-unsecured-instance-of-jupyter-hub-just-to-see-if-it-works","text":"OK- let's give JupyterHub a whirl. We'll start JupterHub for the first time. Note the --no-ssl flag at the end of the command. This flag needs to be included or you won't be able to browse to the server. Also note we have to have our (jupyterhub) virtual environment active when we run the command. $(jupyterhub) jupyterhub --no-ssl We see some output in the PuTTY window. The last line is something like JupyterHub is now running at http://:8000/ . The first time I set up JupyterHub, I wasn't able to see the site using a web browser. No web page loaded, and the connection timed out. Why? It turns out Digital Ocean installs a firewall called ufw by default and turns the ufw firewall on. When the server was created, ufw was configured to only allow incoming connections on ports 22, 80 and 433. The output below is shown when we first log into the Digital Ocean server: \"ufw\" has been enabled. All ports except 22 (SSH), 80 (http) and 443 (https) have been blocked by default. But JupyterHub runs on port 8000 - it tells us so when JupyterHub starts. So we need to configure ufw to allow connections on port 8000 (at least for now, just to see if JupyterHub works). To allow communication on port 8000 and start JupyterHub, type: $(jupyterhub) sudo ufw allow 8000 # make sure the (jupyterhub) conda env is activated $(jupyterhub) jupyterhub --no-ssl Now we can browse to the server IP address of our Digital Ocean Droplet appended with :8000 . The web address should look something like: http://165.228.68.178:8000 . You can find the IP address of the server by going into the Digital Ocean dashboard. The JupyterHub login screen looks like: Awesome! Quick log into JupyterHub using the username and password for the non-root sudo user (in my case peter ) that we set up earlier and are running as in our current PuTTY session. You should see the typical notebook file browser with all the files you can see when you run ls ~/ . Try creating and running a new Jupyter notebook. The notebook works just like a Jupyter notebook running locally .","title":"Run a very unsecured instance of Jupyter Hub just to see if it works"},{"location":"install_jupyterhub/#quick-log-out-and-shut-down-jupyterhub","text":"Warning Warning! You should not run JupyterHub without SSL encryption on a public network. Quick! Log out and shut down JupyterHub . (does quick really matter in internet security?) The site is running without any ssl security over regular HTTP not HTTPS. Key in [Ctrl] + [c] to stop JupyterHub. After you have confirmed that JupyterHub works, close off Port 8000 on the server by keying in the following command. $(jupyterhub) sudo ufw deny 8000 $(jupyterhub) sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 DENY Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) DENY Anywhere (v6)","title":"Quick! Log out and shut down JupyterHub"},{"location":"install_jupyterhub/#summary","text":"In this section, we installed Miniconda onto the server. We made sure Miniconda was installed in the /opt directory and then changed the directory permissions so that our non-root sudo user can use the Miniconda installation. Next we created a Python 3.7 virtual environment and installed NumPy, Matplotlib, Pandas, xlrd, and Jupyter into it. Then we installed JupyterLab and JupyterHub into the virtual environment from the conda-forge channel. Finally we ran a very un-secure instance of JupyterHub with no SSL encryption. Running JupyterHub without SSL encryption is NOT ADVISED .","title":"Summary"},{"location":"install_jupyterhub/#next-steps","text":"The next step is to acquire a domain name and link the domain name to our Digital Ocean server.","title":"Next Steps"},{"location":"jupyterhub_config/","text":"JupyterHub Configuration Next, we'll create a jupyterhub_config.py file and modify it to include our cookie secret and proxy auth token. JupyterHub Configuration Create jupyterhub_config.py Modify jupyterhub_config.py Restart Nginx and start Jupyterhub, see if we can login Summary Next Steps Create jupyterhub_config.py We'll create the JupyterHub config file in the /etc/jupyterhub directory. After the directory is created, we need to modify the directory permissions. Then cd into it create the config file with the command jupyterhub --generate-config . Make sure you are in the (jupyterhub) virtual environment when you run the command. $ cd /etc $ sudo mkdir jupyterhub $ sudo chown -R root:peter jupyterhub/ $ sudo chmod -R g+rwx jupyterhub/ $ cd jupyterhub $ conda activate jupyterhub (jupyterhub)$ jupyterhub --generate-config (jupyterhub)$ ls jupyterhub_config.py Modify jupyterhub_config.py Now we'll modify the jupyterhub_config.py file to allow local spawners and include our user peter as an admin user: $ nano jupyterhub_config.py There will be a lot of commented out text in the jupyterhub_config.py file. At the top of the file, add the following: # /etc/jupyterhub/jupyterhub_config.py # PAM Authenticator c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhub/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # Users c.Authenticator.whitelist = {'peter'} c.Authenticator.admin_users = {'peter'} ... Restart Nginx and start Jupyterhub, see if we can login Now we'll restart Nginx. If it seems like Nginx isn't working, try $ sudo systemctl status nginx and see if Nginx really started. If it didn't, try the command nginx -t . This command prints out any error messages if Nginx failed to start. I had to trouble shoot the Nginx configuration many a lot before I got Nginx and JupyterHub working together. $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit Once Nginx is running, try to restart JupyterHub without the --no-ssl flag. Make sure the (jupyterhubenv) virtual environment is active before running the jupyterhub command. $ cd /etc/jupyterhub $ conda activate jupyterhub (jupyterhub)$ jupyterhub Expect to get an error at this point due to the permissions we set for our cookie_secret and proxy_auth_token files. Since these files are set to permissions that only the sudo owner can read and write, running JupyterHub as the user peter won't work. When JupyterHub starts up, it won't be able to access the cookie_secret and proxy_auth_token files. We will remedy this situation in the next step: running JupyterHub as a system service. The system service will run as root and the permissions we set for the cookie_secret and proxy_auth_token files will not be a problem. Summary In this section we created a jupyterhub_config.py file and included a minimal configuration to use the local PAM authenticator (Linux login usernames and passwords). We restarted Nginx, but could not run JupyterHub because of the permissions set to the cookie_secret and proxy_auth_token files. Next Steps The next step is to run JupyterHub as a system service. This allows JupyterHub to run continuously even if we aren't logged into the server. It also allows us to work on our JupyterHub deployment while it is still running.","title":"JupyterHub Configuration"},{"location":"jupyterhub_config/#jupyterhub-configuration","text":"Next, we'll create a jupyterhub_config.py file and modify it to include our cookie secret and proxy auth token. JupyterHub Configuration Create jupyterhub_config.py Modify jupyterhub_config.py Restart Nginx and start Jupyterhub, see if we can login Summary Next Steps","title":"JupyterHub Configuration"},{"location":"jupyterhub_config/#create-jupyterhub_configpy","text":"We'll create the JupyterHub config file in the /etc/jupyterhub directory. After the directory is created, we need to modify the directory permissions. Then cd into it create the config file with the command jupyterhub --generate-config . Make sure you are in the (jupyterhub) virtual environment when you run the command. $ cd /etc $ sudo mkdir jupyterhub $ sudo chown -R root:peter jupyterhub/ $ sudo chmod -R g+rwx jupyterhub/ $ cd jupyterhub $ conda activate jupyterhub (jupyterhub)$ jupyterhub --generate-config (jupyterhub)$ ls jupyterhub_config.py","title":"Create jupyterhub_config.py"},{"location":"jupyterhub_config/#modify-jupyterhub_configpy","text":"Now we'll modify the jupyterhub_config.py file to allow local spawners and include our user peter as an admin user: $ nano jupyterhub_config.py There will be a lot of commented out text in the jupyterhub_config.py file. At the top of the file, add the following: # /etc/jupyterhub/jupyterhub_config.py # PAM Authenticator c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhub/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # Users c.Authenticator.whitelist = {'peter'} c.Authenticator.admin_users = {'peter'} ...","title":"Modify jupyterhub_config.py"},{"location":"jupyterhub_config/#restart-nginx-and-start-jupyterhub-see-if-we-can-login","text":"Now we'll restart Nginx. If it seems like Nginx isn't working, try $ sudo systemctl status nginx and see if Nginx really started. If it didn't, try the command nginx -t . This command prints out any error messages if Nginx failed to start. I had to trouble shoot the Nginx configuration many a lot before I got Nginx and JupyterHub working together. $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit Once Nginx is running, try to restart JupyterHub without the --no-ssl flag. Make sure the (jupyterhubenv) virtual environment is active before running the jupyterhub command. $ cd /etc/jupyterhub $ conda activate jupyterhub (jupyterhub)$ jupyterhub Expect to get an error at this point due to the permissions we set for our cookie_secret and proxy_auth_token files. Since these files are set to permissions that only the sudo owner can read and write, running JupyterHub as the user peter won't work. When JupyterHub starts up, it won't be able to access the cookie_secret and proxy_auth_token files. We will remedy this situation in the next step: running JupyterHub as a system service. The system service will run as root and the permissions we set for the cookie_secret and proxy_auth_token files will not be a problem.","title":"Restart Nginx and start Jupyterhub, see if we can login"},{"location":"jupyterhub_config/#summary","text":"In this section we created a jupyterhub_config.py file and included a minimal configuration to use the local PAM authenticator (Linux login usernames and passwords). We restarted Nginx, but could not run JupyterHub because of the permissions set to the cookie_secret and proxy_auth_token files.","title":"Summary"},{"location":"jupyterhub_config/#next-steps","text":"The next step is to run JupyterHub as a system service. This allows JupyterHub to run continuously even if we aren't logged into the server. It also allows us to work on our JupyterHub deployment while it is still running.","title":"Next Steps"},{"location":"jupyterlab_default_interface/","text":"JupyterLab Default Interface Over the summer, when I ran JupterHub for the first time, we used the regular Jupyter notebook interface. There is an option when deploying JupyterHub to use the new JupyterLab interface instead. JupyterLab Default Interface JupyterLab Interface Modify jupyterhub_config.py Restart JupyterHub Install JupyterLab extension for JupyterHub Restart JupyterHub Summary JupyterLab Interface Below is the file browser running the regular Jupyter notebook interface. This is what students see now when they log into JupyterHub. But students could also be greeted by the JupyterLab interface after they log in. Luckily, the JupyterLab interface is built right into JupyterHub. We can access the JupyterLab interface by logging into JupyerHub and modifying the URL. Below is the URL when you are logged into the notebook file browser: https://mydomain.org/user/user.name/tree In the URL, if we remove /tree and replace it with /lab the result is the JupyterLab interface. https://mydomain.org/user/user.name/lab The resulting JupyterLab interface is shown below: We can get back to the regular notebook interface by replacing /lab with /tree . The regular Jupyter notebook interface, running a notebook, is shown below: If we switch to the JupyterLab interface, the same notebook looks like this: Modify jupyterhub_config.py To use JupyterLab as the default landing page (instead of the regular notebook interface), add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory. # /etc/jupyterhub/jupyterhub_config.py ... # Start Users at the JupyterLab Interface c.Spawner.default_url = '/lab' ... That's it. It's that easy to switch between the regular notebook and JupyterLab interfaces. Restart JupyterHub After jupyterhub_config.py is saved, let's restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit the status panel When we log into JupyterHub, we are greated by the JupyterLab interface: Install JupyterLab extension for JupyterHub One advantage of the good old classic notebook interface is it contains buttons to login and logout of JupyterHub, and buttons to start and stop our server. Login/logout and server start/stop controls are absent from the JupyterLab interface. Luckily, these controls can be added into JupyterLab with the JupyterHub extension for JupyterLab . To install the JupyterLab extension for JupyterHub, log into the server, then activate the (jupyterhub) virtual environment. The extenion is installed with the command below: $ conda activate jupyterhub (jupyterhub)$ jupyter labextension install @jupyterlab/hub-extension I had to run this command twice to get the extension to install. Don't know why. The first time I ran the command, I was greeted by an error about installing or using yarn . But when I ran it a second time, it worked. To use JupyterLab extension, add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory: # /etc/jupyterhub/jupyterhub_config.py ... # Use the JupyterLab extension for JupyterHub. # install with $ jupyter labextension install @jupyterlab/hub-extension c.Spawner.cmd = ['jupyter-labhub'] ... Restart JupyterHub After jupyterhub_config.py is saved, restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit the status panel When we log into JupyterHub, we see the JupyterLab interface with a new [Hub] menu along the top: If you select [Control Pannel], you end up with same buttons contained in the Jupyter notebook interface. If we [Stop My Server], then re-[Start My Server], we end up back in the JupyterLab interface. Summary The JupyterLab interface is the newest Jupyter notebook interface created by the Jupyter project team. The JupyterLab interface includes a file browser in the left-hand side and the option of splitting up a window to show multiple notebooks. Setting the JupyterLab interface as default is as simple as adding a custom URL to the jupyterhub_config.py file. If JupyterLab is the default interface, it is also helpful to add the JupyterHub extension for the JupyterLab interface. This extension adds the [Stop Server] and [Start Server] buttons to JupyterLab under a [Hub] menu item.","title":"JupyterLab Default Interface"},{"location":"jupyterlab_default_interface/#jupyterlab-default-interface","text":"Over the summer, when I ran JupterHub for the first time, we used the regular Jupyter notebook interface. There is an option when deploying JupyterHub to use the new JupyterLab interface instead. JupyterLab Default Interface JupyterLab Interface Modify jupyterhub_config.py Restart JupyterHub Install JupyterLab extension for JupyterHub Restart JupyterHub Summary","title":"JupyterLab Default Interface"},{"location":"jupyterlab_default_interface/#jupyterlab-interface","text":"Below is the file browser running the regular Jupyter notebook interface. This is what students see now when they log into JupyterHub. But students could also be greeted by the JupyterLab interface after they log in. Luckily, the JupyterLab interface is built right into JupyterHub. We can access the JupyterLab interface by logging into JupyerHub and modifying the URL. Below is the URL when you are logged into the notebook file browser: https://mydomain.org/user/user.name/tree In the URL, if we remove /tree and replace it with /lab the result is the JupyterLab interface. https://mydomain.org/user/user.name/lab The resulting JupyterLab interface is shown below: We can get back to the regular notebook interface by replacing /lab with /tree . The regular Jupyter notebook interface, running a notebook, is shown below: If we switch to the JupyterLab interface, the same notebook looks like this:","title":"JupyterLab Interface"},{"location":"jupyterlab_default_interface/#modify-jupyterhub_configpy","text":"To use JupyterLab as the default landing page (instead of the regular notebook interface), add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory. # /etc/jupyterhub/jupyterhub_config.py ... # Start Users at the JupyterLab Interface c.Spawner.default_url = '/lab' ... That's it. It's that easy to switch between the regular notebook and JupyterLab interfaces.","title":"Modify jupyterhub_config.py"},{"location":"jupyterlab_default_interface/#restart-jupyterhub","text":"After jupyterhub_config.py is saved, let's restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit the status panel When we log into JupyterHub, we are greated by the JupyterLab interface:","title":"Restart JupyterHub"},{"location":"jupyterlab_default_interface/#install-jupyterlab-extension-for-jupyterhub","text":"One advantage of the good old classic notebook interface is it contains buttons to login and logout of JupyterHub, and buttons to start and stop our server. Login/logout and server start/stop controls are absent from the JupyterLab interface. Luckily, these controls can be added into JupyterLab with the JupyterHub extension for JupyterLab . To install the JupyterLab extension for JupyterHub, log into the server, then activate the (jupyterhub) virtual environment. The extenion is installed with the command below: $ conda activate jupyterhub (jupyterhub)$ jupyter labextension install @jupyterlab/hub-extension I had to run this command twice to get the extension to install. Don't know why. The first time I ran the command, I was greeted by an error about installing or using yarn . But when I ran it a second time, it worked. To use JupyterLab extension, add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory: # /etc/jupyterhub/jupyterhub_config.py ... # Use the JupyterLab extension for JupyterHub. # install with $ jupyter labextension install @jupyterlab/hub-extension c.Spawner.cmd = ['jupyter-labhub'] ...","title":"Install JupyterLab extension for JupyterHub"},{"location":"jupyterlab_default_interface/#restart-jupyterhub_1","text":"After jupyterhub_config.py is saved, restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit the status panel When we log into JupyterHub, we see the JupyterLab interface with a new [Hub] menu along the top: If you select [Control Pannel], you end up with same buttons contained in the Jupyter notebook interface. If we [Stop My Server], then re-[Start My Server], we end up back in the JupyterLab interface.","title":"Restart JupyterHub"},{"location":"jupyterlab_default_interface/#summary","text":"The JupyterLab interface is the newest Jupyter notebook interface created by the Jupyter project team. The JupyterLab interface includes a file browser in the left-hand side and the option of splitting up a window to show multiple notebooks. Setting the JupyterLab interface as default is as simple as adding a custom URL to the jupyterhub_config.py file. If JupyterLab is the default interface, it is also helpful to add the JupyterHub extension for the JupyterLab interface. This extension adds the [Stop Server] and [Start Server] buttons to JupyterLab under a [Hub] menu item.","title":"Summary"},{"location":"nbgitpuller_plugin/","text":"nbgitpuller Plugin In this section, we will install, enable and test the nbgitpuller plugin. The nbgitpuller plugin is a JupyterHub extension that pulls down a GitHub repo into each student's JupyterHub environment when students start JupyterHub by clicking on a specific link. The repo for the nbgitpuller plugin is here: https://github.com/jupyterhub/nbgitpuller#constructing-the-nbgitpuller-url The link to the auto-generated URL construction app is here: https://jupyterhub.github.io/nbgitpuller/link Install the nbgitpuller plugin To install the nbgitpuller plugin for JupyterHub, first log into the server and stop JupyterHub. Then activate the (jupyterhub) virtual environment and pip install the plugin. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ pip install nbgitpuller After the nbgitpuller plugin is installed, the plugin needs to be enabled. (jupyterhubenv)$ jupyter serverextension enable --py nbgitpuller --sys-prefix (jupyterhubenv)$ conda deactivate $ After the serverextension enable command, Jupyter will validate the plugin. The output should look something like below: Enabling: nbgitpuller - Writing config: /opt/miniconda3/envs/jupyterhub/etc/jupyter - Validating... nbgitpuller 0.6.1 OK Restart JupyterHub After the plugin is installed and enabled, restart JupyterHub and check the status. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit It's not a bad idea at this point to try and log into JupyterHub with a web browser and make sure everything still works the same as it did before we installed the nbgitpuller extension. Build custom URL Go to the following link to the nbgitpuller URL builder app. https://jupyterhub.github.io/nbgitpuller/link The URL building tool is shown below. Note the tree/ENGR101/course_materials path shown in the [URL path] text box. Including tree/ENGR101/course_materials plops students into the course_materials directory of the ENGR101 repo when the log into JupyterHub. Initially, I set the URL up so that students were dumped into the repo root. But I thought is looked a little confusing for the students to see the LICENSE , README.md , and requirements.txt files. So I put all the files I wanted students to see in a course_materials directory and routed them to the course_materials directory when Jupyterhub starts. Go to the custom URL Point a browser to the URL generated by the URL builder. The URL will be something like: https://engr101lab.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FProfessorKazarinoff%2FENGR101&urlpath=tree%2FENGR101%2Fcourse_materials First we see the login screen: Once logged in, we see the JupyterLab interface with all the folders and notebooks stored in the GitHub repo we specified. If we open one of the notebooks within JupyterHub, we see the same notebook that is stored on GitHub. The cool thing is that if we modify any of the notes or assignments on GitHub, these modifications will show up when each user logs into JupyterHub. In addition, any files that students create which are not the same file name as files in the GitHub repo will persist on the server. So if a student creates their own file, it stays. But if the instructor upades a file, that update is applied. Pretty neat! Summary In this section we installed the nbgitpuller plugin for JupyterHub. Then we created a custom URL. When we browse to the custom URL, we enter our JupyterHub environment with all the files contained on GitHub placed in our user directory. This is a great plugin to have with JupyterHub. Now when we make changes to the Labs or Assignments in the GitHub Repo, those changes are reflected when students log into JupyterHub with the special URL. Next Steps Next, we'll configure JupyterHub to automatically go the the URL we setup with the nbgitpuller plugin. So when students go to domain.org they get the same files as if they went to the custom plugin URL https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"nbgitpuller Plugin"},{"location":"nbgitpuller_plugin/#nbgitpuller-plugin","text":"In this section, we will install, enable and test the nbgitpuller plugin. The nbgitpuller plugin is a JupyterHub extension that pulls down a GitHub repo into each student's JupyterHub environment when students start JupyterHub by clicking on a specific link. The repo for the nbgitpuller plugin is here: https://github.com/jupyterhub/nbgitpuller#constructing-the-nbgitpuller-url The link to the auto-generated URL construction app is here: https://jupyterhub.github.io/nbgitpuller/link","title":"nbgitpuller Plugin"},{"location":"nbgitpuller_plugin/#install-the-nbgitpuller-plugin","text":"To install the nbgitpuller plugin for JupyterHub, first log into the server and stop JupyterHub. Then activate the (jupyterhub) virtual environment and pip install the plugin. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ pip install nbgitpuller After the nbgitpuller plugin is installed, the plugin needs to be enabled. (jupyterhubenv)$ jupyter serverextension enable --py nbgitpuller --sys-prefix (jupyterhubenv)$ conda deactivate $ After the serverextension enable command, Jupyter will validate the plugin. The output should look something like below: Enabling: nbgitpuller - Writing config: /opt/miniconda3/envs/jupyterhub/etc/jupyter - Validating... nbgitpuller 0.6.1 OK","title":"Install the nbgitpuller plugin"},{"location":"nbgitpuller_plugin/#restart-jupyterhub","text":"After the plugin is installed and enabled, restart JupyterHub and check the status. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit It's not a bad idea at this point to try and log into JupyterHub with a web browser and make sure everything still works the same as it did before we installed the nbgitpuller extension.","title":"Restart JupyterHub"},{"location":"nbgitpuller_plugin/#build-custom-url","text":"Go to the following link to the nbgitpuller URL builder app. https://jupyterhub.github.io/nbgitpuller/link The URL building tool is shown below. Note the tree/ENGR101/course_materials path shown in the [URL path] text box. Including tree/ENGR101/course_materials plops students into the course_materials directory of the ENGR101 repo when the log into JupyterHub. Initially, I set the URL up so that students were dumped into the repo root. But I thought is looked a little confusing for the students to see the LICENSE , README.md , and requirements.txt files. So I put all the files I wanted students to see in a course_materials directory and routed them to the course_materials directory when Jupyterhub starts.","title":"Build custom URL"},{"location":"nbgitpuller_plugin/#go-to-the-custom-url","text":"Point a browser to the URL generated by the URL builder. The URL will be something like: https://engr101lab.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FProfessorKazarinoff%2FENGR101&urlpath=tree%2FENGR101%2Fcourse_materials First we see the login screen: Once logged in, we see the JupyterLab interface with all the folders and notebooks stored in the GitHub repo we specified. If we open one of the notebooks within JupyterHub, we see the same notebook that is stored on GitHub. The cool thing is that if we modify any of the notes or assignments on GitHub, these modifications will show up when each user logs into JupyterHub. In addition, any files that students create which are not the same file name as files in the GitHub repo will persist on the server. So if a student creates their own file, it stays. But if the instructor upades a file, that update is applied. Pretty neat!","title":"Go to the custom URL"},{"location":"nbgitpuller_plugin/#summary","text":"In this section we installed the nbgitpuller plugin for JupyterHub. Then we created a custom URL. When we browse to the custom URL, we enter our JupyterHub environment with all the files contained on GitHub placed in our user directory. This is a great plugin to have with JupyterHub. Now when we make changes to the Labs or Assignments in the GitHub Repo, those changes are reflected when students log into JupyterHub with the special URL.","title":"Summary"},{"location":"nbgitpuller_plugin/#next-steps","text":"Next, we'll configure JupyterHub to automatically go the the URL we setup with the nbgitpuller plugin. So when students go to domain.org they get the same files as if they went to the custom plugin URL https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"Next Steps"},{"location":"nginx_config/","text":"Nginx Configuration The next step is to modify the Nginx config file so that Nginx uses our SSL certificates and routes requests on to JupyterHub. Nginx Configuration Determine number of cores and core limitations Modify nginx.conf Modify sites-available Link sites-available to sites-enabled Test out the new Nginx configuration Summary Next Steps The Nginx configuration step was the hardest part for me when I set up the first JupyterHub server. The Nginx config file isn't Python code or a bash script. I went through many different configurations until I finally got one that worked. The big initial problem was that I copied the sample Nginx config that's up on the JupyterHub docs. But the Nginx config posted on the JupyterHub docs is not a complete Nginx config, it contains just the server portion. I didn't know that the whole server portion needed to be enclosed in another frame. Determine number of cores and core limitations According to this tutorial from Digital Ocean, you can determine the number of cores running on your server and what the limits of those cores are with a couple commands. Information about our server's cores will be put in the Nginx configuration later. The first command determines the number of cores on the server: $ grep processor /proc/cpuinfo | wc -l If this command returns 1 then we have 1 core on your server. Then 1 is the number of worker_processes to set in our Nginx configuration The second command determines the core's limitations: $ ulimit -n If this command returns 1024 , then that's the number of worker_connections we should set in our Nginx configuration. Based on the results of these two commands, we will modify the top of the nginx.conf file worker_processes 1; worker_connections 1024; Modify nginx.conf To modify nginx.conf , cd into the /etc/nginx directory. The nginx.conf file should be there along with a couple other files and directories. $ cd /etc/nginx $ ls conf.d koi-utf nginx.conf sites-available ssl fastcgi.conf koi-win proxy_params sites-enabled uwsgi_params fastcgi_params mime.types scgi_params snippets win-utf $ sudo nano nginx.conf At the top of the file, paste in our information about worker_processes and worker_connections user www-data; worker_processes 1; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 1024; # multi_accept on; } ... Close the configuration file (using [Ctrl]+[x], [y]) and restart Nginx. Check the status to make sure Nginx is active $ sudo systemctl restart nginx $ sudo systemctl status nginx You should see that Nginx is activate and running. Next we will add a map block to the nginx.conf file to ensure http connections are upgraded. In nginx.conf find the lines: ... include /etc/nginx/mime.types; default_type application/octet-stream; ... Replace the block above with the block below: ... include /etc/nginx/mime.types; default_type application/octet-stream; map $http_upgrade $connection_upgrade { default upgrade; '' close; } ... Save the nginx.conf file and restart Nginx again and check the status: $ sudo systemctl restart nginx $ sudo systemctl status nginx Nginx should be running fine with no errors. Modify sites-available According to this tutorial and [this tutorial], we should modify the sites-available file and create a symbolic link to the sites-enabled file. The nginx.conf file shows that it will include /etc/nginx/sites-enabled/* . Open a new file in /etc/nginx/sites-available called jupyterhub $ sudo nano /etc/nginx/sites-available/jupyterhub Paste the following server blocks into the file: # /etc/nginx/sites-available/jupyterhub # All regular http requests on port 80 become SSL/HTTPS requests on port 32 server { listen 80; server_name mydomain.org; # Tell all requests to port 80 to be 302 redirected to HTTPS return 302 https://$host$request_uri; } server { #listen 443 ssl default_server; listen 443; ssl on; # !!! make sure to change to your domain name !!! server_name engr101lab.org; ## SSL Protocals ssl_certificate /etc/letsencrypt/live/engr101lab.org/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/engr101lab.org/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_dhparam /srv/jupyterhub/dhparam.pem; # Make site accessible from http://localhost/ server_name localhost; certs sent to the client in SERVER HELLO are concatenated in ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_stapling on; ssl_stapling_verify on; # modern configuration. tweak to your needs. ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'; # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months) add_header Strict-Transport-Security max-age=15768000; location / { proxy_pass http://127.0.0.1:8000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; #proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ /.well-known { allow all; } } Save and close the `/etc/nginx/sites-available/jupyterhub file. Link sites-available to sites-enabled Now that we have a jupyterhub server configuration in the sites-available directory, we need to create a symbolic link to the sites-enabled directory so the server blocks we wrote will be run by Nginx. To create the symbolic link, use the command below: $ sudo ln -s /etc/nginx/sites-available/jupyterhub /etc/nginx/sites-enabled Test out the new Nginx configuration OK, fingers crossed... Now we are going to check if our Nginx configuration is valid and works correctly. First we can check for configuration errors with the command below: $ sudo nginx -t What we are looking for is output like below. If there are any errors, you need to go back and trouble shoot the Nginx configuration. nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful Now restart Nginx and take a look at the status. $ sudo systemctl restart nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit We are looking for something like: Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2019-02-07 00:40:10 UTC; 7s ago Now browse to the domain name we added to the server. If you use http://mydomain.org you should be re-directed to https://mydomain.org . Since JupyterHub isn't hooked up to Nginx yet, you should see a 502 Bad Gateway Error. But that error should show nginx in the error text. Summary In this section we modified the nginx.conf file and created a server configuration in /etc/nginx/sites-available . Then we created a symbolic link betweeefile in sites-available to sites-enabled Then we checked the Nginx configuration was valid and restarted Nginx. Next Steps The next step configure JupyterHub by creating and modifying a jupyterhub_config.py file.","title":"Nginx Configuration"},{"location":"nginx_config/#nginx-configuration","text":"The next step is to modify the Nginx config file so that Nginx uses our SSL certificates and routes requests on to JupyterHub. Nginx Configuration Determine number of cores and core limitations Modify nginx.conf Modify sites-available Link sites-available to sites-enabled Test out the new Nginx configuration Summary Next Steps The Nginx configuration step was the hardest part for me when I set up the first JupyterHub server. The Nginx config file isn't Python code or a bash script. I went through many different configurations until I finally got one that worked. The big initial problem was that I copied the sample Nginx config that's up on the JupyterHub docs. But the Nginx config posted on the JupyterHub docs is not a complete Nginx config, it contains just the server portion. I didn't know that the whole server portion needed to be enclosed in another frame.","title":"Nginx Configuration"},{"location":"nginx_config/#determine-number-of-cores-and-core-limitations","text":"According to this tutorial from Digital Ocean, you can determine the number of cores running on your server and what the limits of those cores are with a couple commands. Information about our server's cores will be put in the Nginx configuration later. The first command determines the number of cores on the server: $ grep processor /proc/cpuinfo | wc -l If this command returns 1 then we have 1 core on your server. Then 1 is the number of worker_processes to set in our Nginx configuration The second command determines the core's limitations: $ ulimit -n If this command returns 1024 , then that's the number of worker_connections we should set in our Nginx configuration. Based on the results of these two commands, we will modify the top of the nginx.conf file worker_processes 1; worker_connections 1024;","title":"Determine number of cores and core limitations"},{"location":"nginx_config/#modify-nginxconf","text":"To modify nginx.conf , cd into the /etc/nginx directory. The nginx.conf file should be there along with a couple other files and directories. $ cd /etc/nginx $ ls conf.d koi-utf nginx.conf sites-available ssl fastcgi.conf koi-win proxy_params sites-enabled uwsgi_params fastcgi_params mime.types scgi_params snippets win-utf $ sudo nano nginx.conf At the top of the file, paste in our information about worker_processes and worker_connections user www-data; worker_processes 1; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 1024; # multi_accept on; } ... Close the configuration file (using [Ctrl]+[x], [y]) and restart Nginx. Check the status to make sure Nginx is active $ sudo systemctl restart nginx $ sudo systemctl status nginx You should see that Nginx is activate and running. Next we will add a map block to the nginx.conf file to ensure http connections are upgraded. In nginx.conf find the lines: ... include /etc/nginx/mime.types; default_type application/octet-stream; ... Replace the block above with the block below: ... include /etc/nginx/mime.types; default_type application/octet-stream; map $http_upgrade $connection_upgrade { default upgrade; '' close; } ... Save the nginx.conf file and restart Nginx again and check the status: $ sudo systemctl restart nginx $ sudo systemctl status nginx Nginx should be running fine with no errors.","title":"Modify nginx.conf"},{"location":"nginx_config/#modify-sites-available","text":"According to this tutorial and [this tutorial], we should modify the sites-available file and create a symbolic link to the sites-enabled file. The nginx.conf file shows that it will include /etc/nginx/sites-enabled/* . Open a new file in /etc/nginx/sites-available called jupyterhub $ sudo nano /etc/nginx/sites-available/jupyterhub Paste the following server blocks into the file: # /etc/nginx/sites-available/jupyterhub # All regular http requests on port 80 become SSL/HTTPS requests on port 32 server { listen 80; server_name mydomain.org; # Tell all requests to port 80 to be 302 redirected to HTTPS return 302 https://$host$request_uri; } server { #listen 443 ssl default_server; listen 443; ssl on; # !!! make sure to change to your domain name !!! server_name engr101lab.org; ## SSL Protocals ssl_certificate /etc/letsencrypt/live/engr101lab.org/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/engr101lab.org/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_dhparam /srv/jupyterhub/dhparam.pem; # Make site accessible from http://localhost/ server_name localhost; certs sent to the client in SERVER HELLO are concatenated in ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_stapling on; ssl_stapling_verify on; # modern configuration. tweak to your needs. ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'; # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months) add_header Strict-Transport-Security max-age=15768000; location / { proxy_pass http://127.0.0.1:8000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; #proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ /.well-known { allow all; } } Save and close the `/etc/nginx/sites-available/jupyterhub file.","title":"Modify sites-available"},{"location":"nginx_config/#link-sites-available-to-sites-enabled","text":"Now that we have a jupyterhub server configuration in the sites-available directory, we need to create a symbolic link to the sites-enabled directory so the server blocks we wrote will be run by Nginx. To create the symbolic link, use the command below: $ sudo ln -s /etc/nginx/sites-available/jupyterhub /etc/nginx/sites-enabled","title":"Link sites-available to sites-enabled"},{"location":"nginx_config/#test-out-the-new-nginx-configuration","text":"OK, fingers crossed... Now we are going to check if our Nginx configuration is valid and works correctly. First we can check for configuration errors with the command below: $ sudo nginx -t What we are looking for is output like below. If there are any errors, you need to go back and trouble shoot the Nginx configuration. nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful Now restart Nginx and take a look at the status. $ sudo systemctl restart nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit We are looking for something like: Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2019-02-07 00:40:10 UTC; 7s ago Now browse to the domain name we added to the server. If you use http://mydomain.org you should be re-directed to https://mydomain.org . Since JupyterHub isn't hooked up to Nginx yet, you should see a 502 Bad Gateway Error. But that error should show nginx in the error text.","title":"Test out the new Nginx configuration"},{"location":"nginx_config/#summary","text":"In this section we modified the nginx.conf file and created a server configuration in /etc/nginx/sites-available . Then we created a symbolic link betweeefile in sites-available to sites-enabled Then we checked the Nginx configuration was valid and restarted Nginx.","title":"Summary"},{"location":"nginx_config/#next-steps","text":"The next step configure JupyterHub by creating and modifying a jupyterhub_config.py file.","title":"Next Steps"},{"location":"nginx_install/","text":"Install Nginx Now that the domain name is set up, and we have our SSL keys, the next step is to install Nginx and modify our ufw firewall settings. Install Nginx Add the Nginx app to ufw Summary Next Steps Nginx is an open-source web server that can handle many concurrent web connections at the same time. For the Nginx installation, I followed this tutorial from Digital Ocean. Use PuTTY to connect to the server with the non-root sudo user peter we set up before. Once logged in, we can update the system and install Nginx. $ sudo apt-get update $ sudo apt-get upgrade $ sudo apt-get install nginx Add the Nginx app to ufw Digital Ocean installs a firewall application called ufw . Check out which apps the ufw firewall can work with: $ sudo ufw app list We see a list of available ufw configurations to work with Nginx: Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH We want to allow in both http and https requests. Once a http request comes in, we'll use Nginx to convert the http connection to a https connection. Select 'Nginx Full' . Note the C apitalization in the command: $ sudo ufw allow 'Nginx Full' We can check out which ports ufw is allowing through with: $ sudo ufw status Note the output shows ufw allows Nginx Full. We opened port 8000 earlier, so we could see how JupyterHub works without a domain name or SSL. Once we get Nginx running and hooked up to JupyterHub, we need to remember to close off port 8000 in ufw. We also need to make sure the Port 80 is open to tcp traffic. If Nginx doesn't seem to be working correctly, it may be because ufw isn't allowing traffic in. $ sudo ufw allow 80/tcp Nginx will start running as soon at it is installed. We can see the status with: $ sudo systemctl status nginx In the output, we should see something like below. This mean Nginx is running. Key in [ctrl-c] to exit the status dashboard. Active: active (running) since Thu 2018-05-17 04:51:16 UTC; 15min ago Main PID: 17126 (nginx) CGroup: /system.slice/nginx.service \u251c\u2500\u2500 17126 nginx: master process /usr/sbin/nginx -g daemon on; master_pr \u2514\u2500\u2500 17127 nginx: worker process Now we can browse over to the domain (the domain we set up with Digital Ocean DNS and Doogle Domains) and see the Nginx start page. Summary If this section we installed Nginx on the server and confirmed that it is activate and running. We also changed the rules of our ufw firewall to allow Nginx Full traffic access. If it doesn't seem like Nginx is working right, it might be because ufw is not allowing traffic in over Port 80. Opening Port 80 may solve the problem. Next Steps Now that Nginx is installed, the next step is to configure Nginx to use our SSL certificate and run as a reverse proxy for our JupyterHub server.","title":"Install Nginx"},{"location":"nginx_install/#install-nginx","text":"Now that the domain name is set up, and we have our SSL keys, the next step is to install Nginx and modify our ufw firewall settings. Install Nginx Add the Nginx app to ufw Summary Next Steps Nginx is an open-source web server that can handle many concurrent web connections at the same time. For the Nginx installation, I followed this tutorial from Digital Ocean. Use PuTTY to connect to the server with the non-root sudo user peter we set up before. Once logged in, we can update the system and install Nginx. $ sudo apt-get update $ sudo apt-get upgrade $ sudo apt-get install nginx","title":"Install Nginx"},{"location":"nginx_install/#add-the-nginx-app-to-ufw","text":"Digital Ocean installs a firewall application called ufw . Check out which apps the ufw firewall can work with: $ sudo ufw app list We see a list of available ufw configurations to work with Nginx: Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH We want to allow in both http and https requests. Once a http request comes in, we'll use Nginx to convert the http connection to a https connection. Select 'Nginx Full' . Note the C apitalization in the command: $ sudo ufw allow 'Nginx Full' We can check out which ports ufw is allowing through with: $ sudo ufw status Note the output shows ufw allows Nginx Full. We opened port 8000 earlier, so we could see how JupyterHub works without a domain name or SSL. Once we get Nginx running and hooked up to JupyterHub, we need to remember to close off port 8000 in ufw. We also need to make sure the Port 80 is open to tcp traffic. If Nginx doesn't seem to be working correctly, it may be because ufw isn't allowing traffic in. $ sudo ufw allow 80/tcp Nginx will start running as soon at it is installed. We can see the status with: $ sudo systemctl status nginx In the output, we should see something like below. This mean Nginx is running. Key in [ctrl-c] to exit the status dashboard. Active: active (running) since Thu 2018-05-17 04:51:16 UTC; 15min ago Main PID: 17126 (nginx) CGroup: /system.slice/nginx.service \u251c\u2500\u2500 17126 nginx: master process /usr/sbin/nginx -g daemon on; master_pr \u2514\u2500\u2500 17127 nginx: worker process Now we can browse over to the domain (the domain we set up with Digital Ocean DNS and Doogle Domains) and see the Nginx start page.","title":"Add the Nginx app to ufw"},{"location":"nginx_install/#summary","text":"If this section we installed Nginx on the server and confirmed that it is activate and running. We also changed the rules of our ufw firewall to allow Nginx Full traffic access. If it doesn't seem like Nginx is working right, it might be because ufw is not allowing traffic in over Port 80. Opening Port 80 may solve the problem.","title":"Summary"},{"location":"nginx_install/#next-steps","text":"Now that Nginx is installed, the next step is to configure Nginx to use our SSL certificate and run as a reverse proxy for our JupyterHub server.","title":"Next Steps"},{"location":"periodic_maintenance/","text":"Periodic Maintenance After running JupyterHub for two quarters, there are a couple lessons I've learned about maintenance. Increase server size before class starts Right at the beginning of class, when everyone logs in, the server can get overloaded. So during only class times when 24 students plus 1 instructor will all be logged into the JupyterHub server at the same time, boost the server size to a $40/month or maybe even up to an $80/month server. You can update the server size at the Digital Ocean Dashboard, but the server has to be shut down first at the command line. $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Log onto Digital Ocean and select the project and server running JupyterHub. Make sure the \"power slider\" is set to [off]. Then select the $80/month server and click [Upgrade Server]. Now many students should be able to log in and run JupyterHub at the same time. After the server restarts, Nginx and JupyterHub have to be restared as well. Key in the following commands after the server size is increased and the \"power slider\" is set to [on]. $ sudo systemctl start nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Remeber to drop the server size back down after class ends. You don't want to rack up a huge bill with Digital Ocean. During the rest of the regular week (not during class time), the server can be smaller and cheaper becuase only a few users at a time will be logged in at the same time. Restart server once a week The Hub seems to get sluggish when it has been running for a long time continously. Shutting the down JupyterHub, Nginx, then restarting the server once each week seems like a good idea. To restart the server, first log into JupyterHub and shut down all the student servers. Then from the command line, run: $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Then go to the Digital Ocean dashboard and restart the server. After the server restarts, restart nginx then JupyterHub. $ sudo systemctl start nginx $ sudo systemctl status nginx $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub Extras There are a couple extra docs pages. Browse through these if you want to use the JupyterLab interface, include a GitHub in the JupyterLab interface or try and make the regular domain name go to the nbgitpuller domain name.","title":"Periodic Maintenance"},{"location":"periodic_maintenance/#periodic-maintenance","text":"After running JupyterHub for two quarters, there are a couple lessons I've learned about maintenance.","title":"Periodic Maintenance"},{"location":"periodic_maintenance/#increase-server-size-before-class-starts","text":"Right at the beginning of class, when everyone logs in, the server can get overloaded. So during only class times when 24 students plus 1 instructor will all be logged into the JupyterHub server at the same time, boost the server size to a $40/month or maybe even up to an $80/month server. You can update the server size at the Digital Ocean Dashboard, but the server has to be shut down first at the command line. $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Log onto Digital Ocean and select the project and server running JupyterHub. Make sure the \"power slider\" is set to [off]. Then select the $80/month server and click [Upgrade Server]. Now many students should be able to log in and run JupyterHub at the same time. After the server restarts, Nginx and JupyterHub have to be restared as well. Key in the following commands after the server size is increased and the \"power slider\" is set to [on]. $ sudo systemctl start nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Remeber to drop the server size back down after class ends. You don't want to rack up a huge bill with Digital Ocean. During the rest of the regular week (not during class time), the server can be smaller and cheaper becuase only a few users at a time will be logged in at the same time.","title":"Increase server size before class starts"},{"location":"periodic_maintenance/#restart-server-once-a-week","text":"The Hub seems to get sluggish when it has been running for a long time continously. Shutting the down JupyterHub, Nginx, then restarting the server once each week seems like a good idea. To restart the server, first log into JupyterHub and shut down all the student servers. Then from the command line, run: $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Then go to the Digital Ocean dashboard and restart the server. After the server restarts, restart nginx then JupyterHub. $ sudo systemctl start nginx $ sudo systemctl status nginx $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub","title":"Restart server once a week"},{"location":"periodic_maintenance/#extras","text":"There are a couple extra docs pages. Browse through these if you want to use the JupyterLab interface, include a GitHub in the JupyterLab interface or try and make the regular domain name go to the nbgitpuller domain name.","title":"Extras"},{"location":"server_setup/","text":"Set Up Digital Ocean Server To start the JupyterHub deployment process, we need to set up an Ubuntu 18.04 server hosted by a cloud provider. Set Up Digital Ocean Server Create a new Digital Ocean Droplet Add an SSH Key Log into the server as root over SSH using PuTTY. Create a non-root sudo user Add SSH keys to new user's profile Connect to the server as the non-root sudo user using PuTTY Summary Next Steps Digital Ocean is a cloud service provider like Amazon Web Services (AWS), Google Cloud, Microsoft Azure, and Linode. Digital Ocean provides virtual private servers (called Droplets in Digital Ocean-speak) and online storage of static files (called Spaces in Digital Ocean-speak). We are going to run the JupyterHub server on a Digital Ocean droplet . I like Digital Ocean's prices and web interface. The documentation on Digital Ocean is pretty good too. I already have a Digital Ocean account. I don't remember exactly how I signed up for my Digital Ocean account, but going to this link: https://www.digitalocean.com/ and selecting Sign Up should work. Create a new Digital Ocean Droplet To create a new Digital Ocean Droplet (a new server), log in here: https://cloud.digitalocean.com/login After logging in, I got a verify screen and had to grab my phone and retrieve a six digit code. Ah... the joys of two-factor authentication. Once logged in, the Digital Ocean dashboard looks like this. To create a new project, select [+ New Project]. Give the project a name, description and click [Create Project]. After the project is created, we need to add a new Droplet (server) to our project. Click the [Create] dropdown and select [Droplets]. There are a number of choices to make. These are the ones I selected: Image: Ubuntu 18.04 x64 Size: 1 GB Memory 25GB SSD $5/month Datacenter: San Fransisco 2 Add your SSH keys: New SSH Key Finalize: 1 Droplet, Hostname: jupyterhub-ENGR101-2019Q1 Add an SSH Key Warning Important! You need to add the public SSH key BEFORE creating the droplet The public SSH key we created needs to be shown on the list of keys and the radio box beside it needs to be checked. If the SSH key isn't listed or the SSH key box left unchecked, the SSH key will not be added to the server when the server is first created (and then we won't be able to log in with PuTTY). We need to add our public SSH key and check the key box so we can log onto the server with PuTTY. Under [Add your SSH keys], click [New SSH Key]. A dialog window pops up: Paste the contents of the public SSH key into the [New SSH Key] dialog box. Enter a name for the SSH key that will be saved on Digital Ocean. Then click [Add SSH Key] Then you should see the new SSH Key in the [Add your SSH Keys] region of the new droplets page. Make sure the radio box for the SSH key you just added is checked. A problem I had when I set up my first Digital Ocean droplet was that I did not have the SSH Key radio buttons selected. Therefore, when the server was created, no SSH keys were installed. It is way easier to insert SSH keys into the server when the server is created. It is way harder to add an SSH keys after the server is created. At the bottom of the New Droplet Creation screen in the [Finalize and create] section, make sure to enter a recognizable name for the server and ensure the server is added to the project we created earlier. Click the long green [Create] button at the bottom of the page to create the Droplet. After Droplet creation, you end up at the Digital Ocean main dashboard. Our new Droplet can be seen under [Resources] \u2192 [Droplets]. Note the IP address of the new droplet. We need to IP address to log into our server with PuTTY. Copy the IP address of the droplet to the clipboard. Log into the server as root over SSH using PuTTY. Open PuTTY from the Windows start menu. A couple other parameters need to be set before we log onto the server. parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username root Under Connect \u2192 SSH \u2192 Auth \u2192 Private key file for authentication:, click [Browse...]. Navigate to the private SSH key. The private key ends in a .ppk extension. I had trouble finding the private SSH key when I first set up PuTTY. It turned out the SSH key was saved in the Programfiles\\PuTTY folder. The key was not visible in the Windows file browser because I don't have administrator permissions on my machine at work. I ended up having to create a new SSH key and saved the new key in Documents\\ssh-key (I can access Documents\\ssh-key without administrator privileges). Under Connection \u2192 Data \u2192 Auto-login username: root Back in [Sessions] (the top-most menu item or main page), add the IP address and Port = 22, click [Open] This opens up a new window. The new dark window is remote terminal connected to our server. Create a non-root sudo user Digital Ocean recommends that the servers are run by a non-root user that has sudo access. So after an update, the thing we'll do on the server is create a non-root sudo user. First, let's make sure everything is up to date: $ sudo apt-get update $ sudo apt-get upgrade I followed this tutorial from Digital Ocean to create a non-root sudo user. Create the new user with the adduser command. I called my new user peter . $ adduser peter Set a new password and confirm: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully The user details can be skipped by pressing [Enter]. Then [Y] to complete the new user setup. Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] Now let's give our new user sudo privileges: $ usermod -aG sudo peter The new user account is created and the new user has sudo privileges. We can switch accounts and become the new user with: $ sudo su - peter The new user peter should have sudo privileges. This means when acting as peter we should be able to look in the /root directory. $ sudo ls -la /root If you can see the contents of /root , then the new user peter is set up with sudo access. To exit out of the new sudo user's profile, and get back to using the root profile, type exit at the prompt- But don't close the PuTTY terminal yet. Stay logged in as root for one more step. $ exit Add SSH keys to new user's profile Before we log off, we need to add our SSH keys to our new user's profile on the server. The second time I set up JupyterHub, I had trouble logging in as the non-root user using PuTTY. I could log in as root just fine, but I could not log in as the newly created user peter . When Digital Ocean created the server, the SSH keys (specified on the creation page) were added to the root profile. The new user peter didn't exist when the server was created. The only user on the server at creation time was root . Therefore, no SSH keys were added to the peter profile at server creation time- because the user peter didn't exist yet. Since we want to log into our server as the new non-root user peter , we need to add the same SSH keys saved in the root profile to the peter profile. The SSH keys belong in a file located at /home/peter/.ssh/authorized_keys . This little line will copy the ssh keys from the root profile to the new user's profile. The line comes from this tutorial by Digital Ocean. $ rsync --archive --chown=peter:peter ~/.ssh /home/peter Next, we need to open the ufw firewall to OpenSSH traffic. We we'll communicate with the server over SSH and need the ufw firewall to allow this type of communication through. $ ufw allow OpenSSH $ ufw enable $ ufw status We can see that OpenSSH is now allowed. Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) Now we can exit out of the root profile. This terminates the PuTTY session. $ exit Connect to the server as the non-root sudo user using PuTTY Now that the non-root sudo user is set up and our SSH keys are in /home/<user>/.ssh/authorized_keys/ , let's start a new PuTTY session and log into the server as the new user. Like before, open PuTTY from the Windows Start menu and add the following settings, but this time the Auto-login user name is the name of our new non-root sudo user: parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username peter I also saved the PuTTY session details at this point so that I wouldn't have to re-enter all of the parameters each time I want to log into the server. Enter a name into [Saved Sessions] and click [Save]. Once the parameters are saved in PuTTY, you can simply double-click the profile name to log into the server. Log into the server with Sessions \u2192 [Open] You should see the Digital Ocean login screen again. Note the command prompt will have the new user's name before the @ symbol. Check to see which directory you land in. It should be /home/<username> $ pwd /home/<username> We can see the non-root user's home directory. Let's also make sure we can see into the root user's home directory. If we can view the contents of the /root directory, we know the non-root sudo user has sudo privileges. $ sudo ls -la /root The contents of the /root directory should include a .bashrc file and a .ssh directory. ... -rw-r--r-- 1 root root 3106 Apr 9 2018 .bashrc drwx------ 2 root root 4096 Feb 6 00:29 .cache -rw-r--r-- 1 root root 0 Feb 6 00:24 .cloud-locale-test.skip drwx------ 3 root root 4096 Feb 6 00:29 .gnupg -rw-r--r-- 1 root root 148 Aug 17 2015 .profile drwx------ 2 root root 4096 Feb 6 00:24 .ssh To log out of the server simply type exit . The exit command closes the PuTTY session. $ exit Summary In this section, we accomplished a lot. First we created an account on Digital Ocean and logged into the Digital Ocean Dashboard. Then we created a new project on Digital Ocean. Next we created a new Digital Ocean Droplet (a new server) and made sure the new Droplet had our SSH keys saved when the Droplet was created. After we created the Droplet, we logged into the server as root and created a new non-root sudo user. Before we exited out of the root profile, we made sure to save the SSH keys from the root user's profile and add these SSH keys to the non-root sudo user's profile. Finally we logged into the server as the non-root sudo user and made sure the new non-root user has sudo privileges. Next Steps The next step is to install Python and JupyterHub on the server. In particular, we will install Miniconda , create a virtual environment, and install JupyterHub into the virtual environment.","title":"Server Setup"},{"location":"server_setup/#set-up-digital-ocean-server","text":"To start the JupyterHub deployment process, we need to set up an Ubuntu 18.04 server hosted by a cloud provider. Set Up Digital Ocean Server Create a new Digital Ocean Droplet Add an SSH Key Log into the server as root over SSH using PuTTY. Create a non-root sudo user Add SSH keys to new user's profile Connect to the server as the non-root sudo user using PuTTY Summary Next Steps Digital Ocean is a cloud service provider like Amazon Web Services (AWS), Google Cloud, Microsoft Azure, and Linode. Digital Ocean provides virtual private servers (called Droplets in Digital Ocean-speak) and online storage of static files (called Spaces in Digital Ocean-speak). We are going to run the JupyterHub server on a Digital Ocean droplet . I like Digital Ocean's prices and web interface. The documentation on Digital Ocean is pretty good too. I already have a Digital Ocean account. I don't remember exactly how I signed up for my Digital Ocean account, but going to this link: https://www.digitalocean.com/ and selecting Sign Up should work.","title":"Set Up Digital Ocean Server"},{"location":"server_setup/#create-a-new-digital-ocean-droplet","text":"To create a new Digital Ocean Droplet (a new server), log in here: https://cloud.digitalocean.com/login After logging in, I got a verify screen and had to grab my phone and retrieve a six digit code. Ah... the joys of two-factor authentication. Once logged in, the Digital Ocean dashboard looks like this. To create a new project, select [+ New Project]. Give the project a name, description and click [Create Project]. After the project is created, we need to add a new Droplet (server) to our project. Click the [Create] dropdown and select [Droplets]. There are a number of choices to make. These are the ones I selected: Image: Ubuntu 18.04 x64 Size: 1 GB Memory 25GB SSD $5/month Datacenter: San Fransisco 2 Add your SSH keys: New SSH Key Finalize: 1 Droplet, Hostname: jupyterhub-ENGR101-2019Q1","title":"Create a new Digital Ocean Droplet"},{"location":"server_setup/#add-an-ssh-key","text":"Warning Important! You need to add the public SSH key BEFORE creating the droplet The public SSH key we created needs to be shown on the list of keys and the radio box beside it needs to be checked. If the SSH key isn't listed or the SSH key box left unchecked, the SSH key will not be added to the server when the server is first created (and then we won't be able to log in with PuTTY). We need to add our public SSH key and check the key box so we can log onto the server with PuTTY. Under [Add your SSH keys], click [New SSH Key]. A dialog window pops up: Paste the contents of the public SSH key into the [New SSH Key] dialog box. Enter a name for the SSH key that will be saved on Digital Ocean. Then click [Add SSH Key] Then you should see the new SSH Key in the [Add your SSH Keys] region of the new droplets page. Make sure the radio box for the SSH key you just added is checked. A problem I had when I set up my first Digital Ocean droplet was that I did not have the SSH Key radio buttons selected. Therefore, when the server was created, no SSH keys were installed. It is way easier to insert SSH keys into the server when the server is created. It is way harder to add an SSH keys after the server is created. At the bottom of the New Droplet Creation screen in the [Finalize and create] section, make sure to enter a recognizable name for the server and ensure the server is added to the project we created earlier. Click the long green [Create] button at the bottom of the page to create the Droplet. After Droplet creation, you end up at the Digital Ocean main dashboard. Our new Droplet can be seen under [Resources] \u2192 [Droplets]. Note the IP address of the new droplet. We need to IP address to log into our server with PuTTY. Copy the IP address of the droplet to the clipboard.","title":"Add an SSH Key"},{"location":"server_setup/#log-into-the-server-as-root-over-ssh-using-putty","text":"Open PuTTY from the Windows start menu. A couple other parameters need to be set before we log onto the server. parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username root Under Connect \u2192 SSH \u2192 Auth \u2192 Private key file for authentication:, click [Browse...]. Navigate to the private SSH key. The private key ends in a .ppk extension. I had trouble finding the private SSH key when I first set up PuTTY. It turned out the SSH key was saved in the Programfiles\\PuTTY folder. The key was not visible in the Windows file browser because I don't have administrator permissions on my machine at work. I ended up having to create a new SSH key and saved the new key in Documents\\ssh-key (I can access Documents\\ssh-key without administrator privileges). Under Connection \u2192 Data \u2192 Auto-login username: root Back in [Sessions] (the top-most menu item or main page), add the IP address and Port = 22, click [Open] This opens up a new window. The new dark window is remote terminal connected to our server.","title":"Log into the server as root over SSH using PuTTY."},{"location":"server_setup/#create-a-non-root-sudo-user","text":"Digital Ocean recommends that the servers are run by a non-root user that has sudo access. So after an update, the thing we'll do on the server is create a non-root sudo user. First, let's make sure everything is up to date: $ sudo apt-get update $ sudo apt-get upgrade I followed this tutorial from Digital Ocean to create a non-root sudo user. Create the new user with the adduser command. I called my new user peter . $ adduser peter Set a new password and confirm: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully The user details can be skipped by pressing [Enter]. Then [Y] to complete the new user setup. Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] Now let's give our new user sudo privileges: $ usermod -aG sudo peter The new user account is created and the new user has sudo privileges. We can switch accounts and become the new user with: $ sudo su - peter The new user peter should have sudo privileges. This means when acting as peter we should be able to look in the /root directory. $ sudo ls -la /root If you can see the contents of /root , then the new user peter is set up with sudo access. To exit out of the new sudo user's profile, and get back to using the root profile, type exit at the prompt- But don't close the PuTTY terminal yet. Stay logged in as root for one more step. $ exit","title":"Create a non-root sudo user"},{"location":"server_setup/#add-ssh-keys-to-new-users-profile","text":"Before we log off, we need to add our SSH keys to our new user's profile on the server. The second time I set up JupyterHub, I had trouble logging in as the non-root user using PuTTY. I could log in as root just fine, but I could not log in as the newly created user peter . When Digital Ocean created the server, the SSH keys (specified on the creation page) were added to the root profile. The new user peter didn't exist when the server was created. The only user on the server at creation time was root . Therefore, no SSH keys were added to the peter profile at server creation time- because the user peter didn't exist yet. Since we want to log into our server as the new non-root user peter , we need to add the same SSH keys saved in the root profile to the peter profile. The SSH keys belong in a file located at /home/peter/.ssh/authorized_keys . This little line will copy the ssh keys from the root profile to the new user's profile. The line comes from this tutorial by Digital Ocean. $ rsync --archive --chown=peter:peter ~/.ssh /home/peter Next, we need to open the ufw firewall to OpenSSH traffic. We we'll communicate with the server over SSH and need the ufw firewall to allow this type of communication through. $ ufw allow OpenSSH $ ufw enable $ ufw status We can see that OpenSSH is now allowed. Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) Now we can exit out of the root profile. This terminates the PuTTY session. $ exit","title":"Add SSH keys to new user's profile"},{"location":"server_setup/#connect-to-the-server-as-the-non-root-sudo-user-using-putty","text":"Now that the non-root sudo user is set up and our SSH keys are in /home/<user>/.ssh/authorized_keys/ , let's start a new PuTTY session and log into the server as the new user. Like before, open PuTTY from the Windows Start menu and add the following settings, but this time the Auto-login user name is the name of our new non-root sudo user: parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username peter I also saved the PuTTY session details at this point so that I wouldn't have to re-enter all of the parameters each time I want to log into the server. Enter a name into [Saved Sessions] and click [Save]. Once the parameters are saved in PuTTY, you can simply double-click the profile name to log into the server. Log into the server with Sessions \u2192 [Open] You should see the Digital Ocean login screen again. Note the command prompt will have the new user's name before the @ symbol. Check to see which directory you land in. It should be /home/<username> $ pwd /home/<username> We can see the non-root user's home directory. Let's also make sure we can see into the root user's home directory. If we can view the contents of the /root directory, we know the non-root sudo user has sudo privileges. $ sudo ls -la /root The contents of the /root directory should include a .bashrc file and a .ssh directory. ... -rw-r--r-- 1 root root 3106 Apr 9 2018 .bashrc drwx------ 2 root root 4096 Feb 6 00:29 .cache -rw-r--r-- 1 root root 0 Feb 6 00:24 .cloud-locale-test.skip drwx------ 3 root root 4096 Feb 6 00:29 .gnupg -rw-r--r-- 1 root root 148 Aug 17 2015 .profile drwx------ 2 root root 4096 Feb 6 00:24 .ssh To log out of the server simply type exit . The exit command closes the PuTTY session. $ exit","title":"Connect to the server as the non-root sudo user using PuTTY"},{"location":"server_setup/#summary","text":"In this section, we accomplished a lot. First we created an account on Digital Ocean and logged into the Digital Ocean Dashboard. Then we created a new project on Digital Ocean. Next we created a new Digital Ocean Droplet (a new server) and made sure the new Droplet had our SSH keys saved when the Droplet was created. After we created the Droplet, we logged into the server as root and created a new non-root sudo user. Before we exited out of the root profile, we made sure to save the SSH keys from the root user's profile and add these SSH keys to the non-root sudo user's profile. Finally we logged into the server as the non-root sudo user and made sure the new non-root user has sudo privileges.","title":"Summary"},{"location":"server_setup/#next-steps","text":"The next step is to install Python and JupyterHub on the server. In particular, we will install Miniconda , create a virtual environment, and install JupyterHub into the virtual environment.","title":"Next Steps"},{"location":"setup_and_tools/","text":"Set Up and Tools In this section, we'll review the tools we need to install locally get JupyterHub running on a remote sever. Set Up and Tools File Locations and Directory Structure Development tools PuTTY Gen PuTTY FileZilla Anaconda Visual Studio Code Digital Ocean Summary Next Steps Before we launch into the server setup, let's quick review where certain files are going to go on the JupyterHub remote server. File Locations and Directory Structure According to the JuptyerHub docs : The folks at JupyterHub recommend that we put all of the files used by JupyterHub on the server into standard UNIX filesystem locations: /srv/jupyterhub for all security and runtime files /etc/jupyterhub for all configuration files /var/log for log files Development tools PuTTY Gen Before we create the remote server, a set of private/public SSH keys are needed. SSH keys can be created with PuTTY Gen . PuTTY Gen is installed with a typical PuTTY installation. See this post for a details. PuTTY An SSH terminal program is needed to communicate with the server. On Windows 10, I use PuTTY . See this post for details. On MacOS and Linux, SSH from the command line works as well. PuTTY and PuTTY Gen are installed at the same time all in one go. FileZilla It is helpful to have an SFTP client to move large files back and forth between our local computer and the server. On Windows 10, I use FileZilla . Anaconda Locally, I use the Anaconda distribution of Python and the Anaconda Prompt to create virtual environments and run Python code. Visual Studio Code I use a couple of different Python code editors. My two favorites are Visual Studio Code and PyCharm . You can download and install Visual Studio Code here . PyCharm has a community edition which is free, and a professional version which requires a license. For this JupyterHub deployment, I'll just use Visual Studio Code. Digital Ocean This JupyterHub deployment runs on a Digital Ocean virtual private server. You can sign up for a new Digital Ocean account here . Local development and testing was completed on a Windows 10 laptop and desktop. Summary JupyterHub has a set of standard file locations where we will put our configuration and runtime files. Our local computer needs a couple tools installed before we can start working with the cloud server and install JupyterHub: PuTTYgen - create SSH Keys PuTTY - communicate with the server over SSH FileZilla - FTP client Anaconda - local version of Python Visual Studio Code - local code editor Next Steps The next step is to create a public-private SSH key pair with PuTTYgen. We'll use this public-private SSH key to log into the server with PuTTY.","title":"Set Up and Tools"},{"location":"setup_and_tools/#set-up-and-tools","text":"In this section, we'll review the tools we need to install locally get JupyterHub running on a remote sever. Set Up and Tools File Locations and Directory Structure Development tools PuTTY Gen PuTTY FileZilla Anaconda Visual Studio Code Digital Ocean Summary Next Steps Before we launch into the server setup, let's quick review where certain files are going to go on the JupyterHub remote server.","title":"Set Up and Tools"},{"location":"setup_and_tools/#file-locations-and-directory-structure","text":"According to the JuptyerHub docs : The folks at JupyterHub recommend that we put all of the files used by JupyterHub on the server into standard UNIX filesystem locations: /srv/jupyterhub for all security and runtime files /etc/jupyterhub for all configuration files /var/log for log files","title":"File Locations and Directory Structure"},{"location":"setup_and_tools/#development-tools","text":"","title":"Development tools"},{"location":"setup_and_tools/#putty-gen","text":"Before we create the remote server, a set of private/public SSH keys are needed. SSH keys can be created with PuTTY Gen . PuTTY Gen is installed with a typical PuTTY installation. See this post for a details.","title":"PuTTY Gen"},{"location":"setup_and_tools/#putty","text":"An SSH terminal program is needed to communicate with the server. On Windows 10, I use PuTTY . See this post for details. On MacOS and Linux, SSH from the command line works as well. PuTTY and PuTTY Gen are installed at the same time all in one go.","title":"PuTTY"},{"location":"setup_and_tools/#filezilla","text":"It is helpful to have an SFTP client to move large files back and forth between our local computer and the server. On Windows 10, I use FileZilla .","title":"FileZilla"},{"location":"setup_and_tools/#anaconda","text":"Locally, I use the Anaconda distribution of Python and the Anaconda Prompt to create virtual environments and run Python code.","title":"Anaconda"},{"location":"setup_and_tools/#visual-studio-code","text":"I use a couple of different Python code editors. My two favorites are Visual Studio Code and PyCharm . You can download and install Visual Studio Code here . PyCharm has a community edition which is free, and a professional version which requires a license. For this JupyterHub deployment, I'll just use Visual Studio Code.","title":"Visual Studio Code"},{"location":"setup_and_tools/#digital-ocean","text":"This JupyterHub deployment runs on a Digital Ocean virtual private server. You can sign up for a new Digital Ocean account here . Local development and testing was completed on a Windows 10 laptop and desktop.","title":"Digital Ocean"},{"location":"setup_and_tools/#summary","text":"JupyterHub has a set of standard file locations where we will put our configuration and runtime files. Our local computer needs a couple tools installed before we can start working with the cloud server and install JupyterHub: PuTTYgen - create SSH Keys PuTTY - communicate with the server over SSH FileZilla - FTP client Anaconda - local version of Python Visual Studio Code - local code editor","title":"Summary"},{"location":"setup_and_tools/#next-steps","text":"The next step is to create a public-private SSH key pair with PuTTYgen. We'll use this public-private SSH key to log into the server with PuTTY.","title":"Next Steps"},{"location":"ssh_keys/","text":"Create SSH keys SSH keys allow us to log into the Digital Ocean cloud server which will run JupyterHub. SSH keys come in pairs, a private key and a public key. The public key will be stored on the JupyterHub cloud server and the private key will stay on our local machine. Create SSH keys Why SSH keys, PuTTYgen and why do this first? Download PuTTY Start PuTTYgen and create the SSH keys Save SSH public and private keys to Documents folder Copy the public key to clipboard Summary Next Steps Why SSH keys, PuTTYgen and why do this first? When I set up one of my first JupyterHub servers, one of the initial server setup steps was to add SSH keys (so the server has the SSH key when the server is initialized). On that first JupyterHub server, I tried to create and save the SSH keys to the Digital Ocean (the cloud server provider) dashboard so the SSH keys would be on the server when the server first started. But I goofed up somehow; and the server started without any SSH keys. It is a BIG PAIN to add SSH keys after the server starts for the first time. I ended up copying the public SSH key into pastebin.com, logging onto the server with the Digital Ocean console and used wget to bring a text file of the SSH key from pastebin.com onto the server and then used mv to copy the key name into the right location. Ah! I'm pretty sure that pasting a public SSH key into pastebin.com is not the best way to set up a secure server. So to make sure that doesn't happen again, we are going to generate the SSH keys first and set up the server second. SSH keys are needed to use PuTTY (regular PuTTY not PuTTYgen) to log into the server. Since I'm working on Windows 10, using PuTTYgen (a program that comes with PuTTY that generates SSH keys) seems like the easiest solution to generate the SSH keys. Download PuTTY I have already installed PuTTY on my Windows 10 machines at home and at work. The download link is below: Download PuTTY PuTTY seems to want you to install lots of extra stuff when you run the installer. I didn't install any of the \"offers\" that popped up during installation. Start PuTTYgen and create the SSH keys I went through this tutorial about how to set up SSH keys on Windows 10 for Digital Ocean servers. I followed the tutorial steps to create the SSH keys with PuTTYgen. Using the Windows start menu, open PuTTYgen (not regular PuTTY): Use the following parameters: Type of key to generate: RSA Number of bits in generated key: 2048 Then click [Generate] This brings up a dialog to move the mouse around the empty area to generate some randomness. This is my favorite part! Just move the mouse around the dialog box until the progress bar ends. Fun. When the next screen pops up, right-click and copy the contents of the Public Key the the clipboard. We need the public key contents available to paste into the server's SSH authorized_keys file. Include the rsa line in the text copied to the clipboard. Save SSH public and private keys to Documents folder In the [Actions] section click [Save public key] and click [Save private key] Make sure to save both the public and the private key. Save these keys to an accessible folder. The first time I generated SSH keys, I saved the keys in the default location and couldn't access them later. The second time I created SSH keys, I created a folder in the Documents folder called ssh-keys and saved the public and private keys in Documents\\ssh-keys . I saved the public key with the name: public_key_jupyterhub.txt . The Digital Ocean documentation recommends a .txt file extension for the public key (so you can open it and copy the contents). The private key should have a .ppk file extension. Copy the public key to clipboard Before closing PuTTYgen, make sure to copy the contents of the public key to the clipboard. We'll need the public key contents when we create the server. Copy all of the contents of the public SSH key including the ssh-rsa line. Summary After completing these steps, we have a public and private SSH key pair saved in Documents\\ssh-keys . We also have the contents of the public SSH key saved to the clipboard. Next Steps Next, we'll create a new server on Digital Ocean (called a droplet ). Then we'll use the SSH keys we just created to log into the server and create a non-root sudo user.","title":"SSH Keys"},{"location":"ssh_keys/#create-ssh-keys","text":"SSH keys allow us to log into the Digital Ocean cloud server which will run JupyterHub. SSH keys come in pairs, a private key and a public key. The public key will be stored on the JupyterHub cloud server and the private key will stay on our local machine. Create SSH keys Why SSH keys, PuTTYgen and why do this first? Download PuTTY Start PuTTYgen and create the SSH keys Save SSH public and private keys to Documents folder Copy the public key to clipboard Summary Next Steps","title":"Create SSH keys"},{"location":"ssh_keys/#why-ssh-keys-puttygen-and-why-do-this-first","text":"When I set up one of my first JupyterHub servers, one of the initial server setup steps was to add SSH keys (so the server has the SSH key when the server is initialized). On that first JupyterHub server, I tried to create and save the SSH keys to the Digital Ocean (the cloud server provider) dashboard so the SSH keys would be on the server when the server first started. But I goofed up somehow; and the server started without any SSH keys. It is a BIG PAIN to add SSH keys after the server starts for the first time. I ended up copying the public SSH key into pastebin.com, logging onto the server with the Digital Ocean console and used wget to bring a text file of the SSH key from pastebin.com onto the server and then used mv to copy the key name into the right location. Ah! I'm pretty sure that pasting a public SSH key into pastebin.com is not the best way to set up a secure server. So to make sure that doesn't happen again, we are going to generate the SSH keys first and set up the server second. SSH keys are needed to use PuTTY (regular PuTTY not PuTTYgen) to log into the server. Since I'm working on Windows 10, using PuTTYgen (a program that comes with PuTTY that generates SSH keys) seems like the easiest solution to generate the SSH keys.","title":"Why SSH keys, PuTTYgen and why do this first?"},{"location":"ssh_keys/#download-putty","text":"I have already installed PuTTY on my Windows 10 machines at home and at work. The download link is below: Download PuTTY PuTTY seems to want you to install lots of extra stuff when you run the installer. I didn't install any of the \"offers\" that popped up during installation.","title":"Download PuTTY"},{"location":"ssh_keys/#start-puttygen-and-create-the-ssh-keys","text":"I went through this tutorial about how to set up SSH keys on Windows 10 for Digital Ocean servers. I followed the tutorial steps to create the SSH keys with PuTTYgen. Using the Windows start menu, open PuTTYgen (not regular PuTTY): Use the following parameters: Type of key to generate: RSA Number of bits in generated key: 2048 Then click [Generate] This brings up a dialog to move the mouse around the empty area to generate some randomness. This is my favorite part! Just move the mouse around the dialog box until the progress bar ends. Fun. When the next screen pops up, right-click and copy the contents of the Public Key the the clipboard. We need the public key contents available to paste into the server's SSH authorized_keys file. Include the rsa line in the text copied to the clipboard.","title":"Start PuTTYgen and create the SSH keys"},{"location":"ssh_keys/#save-ssh-public-and-private-keys-to-documents-folder","text":"In the [Actions] section click [Save public key] and click [Save private key] Make sure to save both the public and the private key. Save these keys to an accessible folder. The first time I generated SSH keys, I saved the keys in the default location and couldn't access them later. The second time I created SSH keys, I created a folder in the Documents folder called ssh-keys and saved the public and private keys in Documents\\ssh-keys . I saved the public key with the name: public_key_jupyterhub.txt . The Digital Ocean documentation recommends a .txt file extension for the public key (so you can open it and copy the contents). The private key should have a .ppk file extension.","title":"Save SSH public and private keys to Documents folder"},{"location":"ssh_keys/#copy-the-public-key-to-clipboard","text":"Before closing PuTTYgen, make sure to copy the contents of the public key to the clipboard. We'll need the public key contents when we create the server. Copy all of the contents of the public SSH key including the ssh-rsa line.","title":"Copy the public key to clipboard"},{"location":"ssh_keys/#summary","text":"After completing these steps, we have a public and private SSH key pair saved in Documents\\ssh-keys . We also have the contents of the public SSH key saved to the clipboard.","title":"Summary"},{"location":"ssh_keys/#next-steps","text":"Next, we'll create a new server on Digital Ocean (called a droplet ). Then we'll use the SSH keys we just created to log into the server and create a non-root sudo user.","title":"Next Steps"},{"location":"ssl_cirtificates/","text":"Obtain SSL Certificates Now that a domain name is hooked up to our JupyterHub server, we'll be able to obtain an SSL certificate and run JupyterHub over https. I followed this presentation to install certbot , a program used to generate SSL certificates. Obtain SSL Certificates Install and run certbot File Locations and Permissions Summary Next Steps Install and run certbot We'll use certbot to obtain a standalone SSL certificate. Log onto the server with PuTTY. Certbot will need to communicate over the network, so before we run certbot, we need to open up Port 80 using the ufw firewall utility. $ sudo ufw allow 80 The commands below installs certbot, modifies permissions, and runs certbot to obtain the SSL certificate. Make sure to change mydomain.org to the correct domain name. $ cd ~ $ mkdir certbot $ cd certbot $ wget https://dl.eff.org/certbot-auto $ chmod a+x certbot-auto $ ./certbot-auto certonly --standalone -d mydomain.com Certbot will ask you for an email address where it will send certificate renewal notices. Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): Agree to the licencing terms by typing A . You not need to share an email address with the Electronic Frontier Foundation . Getting an email that it is time to renew the SSL certificate like we did above is a good idea though. If Certbot worked, and we get our SSL certificates- the output looks something like below: IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/engr101lab.org/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/engr101lab.org/privkey.pem Your cert will expire on 2019-05-07. To obtain a new or tweaked version of this certificate in the future, simply run certbot-auto again. To non-interactively renew *all* of your certificates, run \"certbot-auto renew\" Note the date when the certificate expires. You will need to log back onto the server before this date and run certbot-auto renew to update the SSL cirt in a few months time. Now that Certbot created our SSL certs, we can close Port 80 using the ufw utility. $ sudo ufw deny 80 File Locations and Permissions Note the location of the fullchain.pem and privkey.pem files. We'll need to put these file paths into our Nginx configuration. We also need to allow Nginx access these .pem files. I had trouble getting Nginx to run and this presentation showed a way to give Nginx access to the SSL key files. There is probably a more \"Linuxy\" way of giving Nginx access to the cert files, but I messed around with the permission settings for a while, and using the commands below worked. $ cd /etc $ cd letsencrypt $ ls -la $ sudo chown :sudo -R archive/ $ sudo chown :sudo -R live/ $ sudo chmod 600 -R archive/ $ sudo chmod 600 -R live/ $ ls -la drwxr-xr-x 9 root root 4096 Feb 6 17:41 . drwxr-xr-x 92 root root 4096 Feb 6 17:36 .. drwx------ 3 root root 4096 Feb 6 17:36 accounts drw------- 3 root sudo 4096 Feb 6 17:41 archive drwxr-xr-x 2 root root 4096 Feb 6 17:41 csr drwx------ 2 root root 4096 Feb 6 17:41 keys drw------- 3 root sudo 4096 Feb 6 17:41 live drwxr-xr-x 2 root root 4096 Feb 6 17:41 renewal drwxr-xr-x 5 root root 4096 Feb 6 17:36 renewal-hooks Summary In this section, we installed Certbot on the server and ran Cerbot to obtain an SSL certificate. One gotcha to remember is that Port 80 must be open to download Certbot. Port 80 also has to be open when Certbot runs. After we obtained our SSL certificate, we noted the location of the the fullchain.pem and privkey.pem files Certbot created. Finally, we changed the permissions of the directories that house the .pem files: /etc/letsencrypt/archive/ and /etc/letsencrypt/archive/ . Next Steps The next step is to create a cookie secret, proxy auth token, and dhparem.pem file.","title":"SSL Certificates"},{"location":"ssl_cirtificates/#obtain-ssl-certificates","text":"Now that a domain name is hooked up to our JupyterHub server, we'll be able to obtain an SSL certificate and run JupyterHub over https. I followed this presentation to install certbot , a program used to generate SSL certificates. Obtain SSL Certificates Install and run certbot File Locations and Permissions Summary Next Steps","title":"Obtain SSL Certificates"},{"location":"ssl_cirtificates/#install-and-run-certbot","text":"We'll use certbot to obtain a standalone SSL certificate. Log onto the server with PuTTY. Certbot will need to communicate over the network, so before we run certbot, we need to open up Port 80 using the ufw firewall utility. $ sudo ufw allow 80 The commands below installs certbot, modifies permissions, and runs certbot to obtain the SSL certificate. Make sure to change mydomain.org to the correct domain name. $ cd ~ $ mkdir certbot $ cd certbot $ wget https://dl.eff.org/certbot-auto $ chmod a+x certbot-auto $ ./certbot-auto certonly --standalone -d mydomain.com Certbot will ask you for an email address where it will send certificate renewal notices. Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): Agree to the licencing terms by typing A . You not need to share an email address with the Electronic Frontier Foundation . Getting an email that it is time to renew the SSL certificate like we did above is a good idea though. If Certbot worked, and we get our SSL certificates- the output looks something like below: IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/engr101lab.org/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/engr101lab.org/privkey.pem Your cert will expire on 2019-05-07. To obtain a new or tweaked version of this certificate in the future, simply run certbot-auto again. To non-interactively renew *all* of your certificates, run \"certbot-auto renew\" Note the date when the certificate expires. You will need to log back onto the server before this date and run certbot-auto renew to update the SSL cirt in a few months time. Now that Certbot created our SSL certs, we can close Port 80 using the ufw utility. $ sudo ufw deny 80","title":"Install and run certbot"},{"location":"ssl_cirtificates/#file-locations-and-permissions","text":"Note the location of the fullchain.pem and privkey.pem files. We'll need to put these file paths into our Nginx configuration. We also need to allow Nginx access these .pem files. I had trouble getting Nginx to run and this presentation showed a way to give Nginx access to the SSL key files. There is probably a more \"Linuxy\" way of giving Nginx access to the cert files, but I messed around with the permission settings for a while, and using the commands below worked. $ cd /etc $ cd letsencrypt $ ls -la $ sudo chown :sudo -R archive/ $ sudo chown :sudo -R live/ $ sudo chmod 600 -R archive/ $ sudo chmod 600 -R live/ $ ls -la drwxr-xr-x 9 root root 4096 Feb 6 17:41 . drwxr-xr-x 92 root root 4096 Feb 6 17:36 .. drwx------ 3 root root 4096 Feb 6 17:36 accounts drw------- 3 root sudo 4096 Feb 6 17:41 archive drwxr-xr-x 2 root root 4096 Feb 6 17:41 csr drwx------ 2 root root 4096 Feb 6 17:41 keys drw------- 3 root sudo 4096 Feb 6 17:41 live drwxr-xr-x 2 root root 4096 Feb 6 17:41 renewal drwxr-xr-x 5 root root 4096 Feb 6 17:36 renewal-hooks","title":"File Locations and Permissions"},{"location":"ssl_cirtificates/#summary","text":"In this section, we installed Certbot on the server and ran Cerbot to obtain an SSL certificate. One gotcha to remember is that Port 80 must be open to download Certbot. Port 80 also has to be open when Certbot runs. After we obtained our SSL certificate, we noted the location of the the fullchain.pem and privkey.pem files Certbot created. Finally, we changed the permissions of the directories that house the .pem files: /etc/letsencrypt/archive/ and /etc/letsencrypt/archive/ .","title":"Summary"},{"location":"ssl_cirtificates/#next-steps","text":"The next step is to create a cookie secret, proxy auth token, and dhparem.pem file.","title":"Next Steps"},{"location":"systemd/","text":"Run JupyterHub as a system service Running JupyerHub as a system service allows JupyterHub to run continuously even if we are not logged into the server. It also keeps JupyterHub running while when we log into the server and make any changes. Run JupyterHub as a system service Test local OAuth Summary Next Steps To run JupyterHub as a system service (according to this wiki ), we need to create a service file in the /etc/systemd/system directory. cd into the directory and have a look around. We see a couple files that end in .service . $ cd /etc/systemd/system $ ls cloud-init.target.wants network-online.target.wants dbus-org.freedesktop.thermald.service paths.target.wants default.target.wants sockets.target.wants final.target.wants sshd.service getty.target.wants sysinit.target.wants graphical.target.wants syslog.service iscsi.service timers.target.wants multi-user.target.wants Create a new .service file called jupyterhub.service pwd /etc.systemd/system $ sudo nano jupyterhub.service In the jupyterhub.service file, add the following. Note that as part of the PATH environment variable /opt/miniconda3/envs/jupyterhub/bin/ is included. This is the path to our virtual environment. As part of the ExecStart= section, we include a flag for our JupyterHub config file located at /etc/jupyterhub/jupyterhub_config.py . [Unit] Description=JupyterHub After=syslog.target network.target [Service] User=root Environment=\"PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/miniconda3/envs/jupyterhub/bin/\" ExecStart=/opt/miniconda3/envs/jupyterhub/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py [Install] WantedBy=multi-user.target Save and exit the nano text editor with [Ctrl]+[x] and [y] then [Enter]. Now we need to reload the system daemon. After the system daemon is reloaded, we can run JupyterHub as a system service using the command: sudo systemctl <start|stop|status> jupyterhub $ sudo systemctl daemon-reload $ sudo systemctl start jupyterhub We can see if JupyterHub is running with: $ sudo systemctl status jupyterhub Loaded: loaded (/etc/systemd/system/jupyterhub.service; Active: active (running) Test local OAuth Now we can point a web browser at our domain name and log into JupyterHub as our non-root user peter and the password we set for peter on the server. This time we are running with SSL security in place and even if we browse to http://mydomain.com , Nginx will forward us to https://mydomain.com . The JupyterHub login screen looks something like the screen capture below: A couple times I thought that JupyterHub was running after using systemctl start jupyterhub , but the JupyterHub wasn't working when I went to the server's web address. It turned out that JupyterHub wasn't running when I keyed in systemctl status jupyterhub . Most times looking for an error and tracking down the the error worked, but one time it seemed to be a problem with the http-configurable-proxy. The following command will shut down the proxy if you get stuck like I did (insert the number corresponding to the configurable-http-proxy process after the kill command): $ ps aux | grep configurable-http-proxy $ kill #### Summary In this section, we got JupyterHub running as a system service. We created a jupyterhub.service file in the /etc/systemd/system/ directory and made sure to include the PATH to our (jupyterhub) virtual environment and the path to our jupyterhub_config.py file. Finally, we reloaded the system service daemon and started the JupyterHub service. Then be opened a web browser and keyed in our domain name and logged into JupyterHub. Next Steps The next step is to add users to our server and see if we can log in as a different user than our non-root sudo user, peter .","title":"System Service"},{"location":"systemd/#run-jupyterhub-as-a-system-service","text":"Running JupyerHub as a system service allows JupyterHub to run continuously even if we are not logged into the server. It also keeps JupyterHub running while when we log into the server and make any changes. Run JupyterHub as a system service Test local OAuth Summary Next Steps To run JupyterHub as a system service (according to this wiki ), we need to create a service file in the /etc/systemd/system directory. cd into the directory and have a look around. We see a couple files that end in .service . $ cd /etc/systemd/system $ ls cloud-init.target.wants network-online.target.wants dbus-org.freedesktop.thermald.service paths.target.wants default.target.wants sockets.target.wants final.target.wants sshd.service getty.target.wants sysinit.target.wants graphical.target.wants syslog.service iscsi.service timers.target.wants multi-user.target.wants Create a new .service file called jupyterhub.service pwd /etc.systemd/system $ sudo nano jupyterhub.service In the jupyterhub.service file, add the following. Note that as part of the PATH environment variable /opt/miniconda3/envs/jupyterhub/bin/ is included. This is the path to our virtual environment. As part of the ExecStart= section, we include a flag for our JupyterHub config file located at /etc/jupyterhub/jupyterhub_config.py . [Unit] Description=JupyterHub After=syslog.target network.target [Service] User=root Environment=\"PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/miniconda3/envs/jupyterhub/bin/\" ExecStart=/opt/miniconda3/envs/jupyterhub/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py [Install] WantedBy=multi-user.target Save and exit the nano text editor with [Ctrl]+[x] and [y] then [Enter]. Now we need to reload the system daemon. After the system daemon is reloaded, we can run JupyterHub as a system service using the command: sudo systemctl <start|stop|status> jupyterhub $ sudo systemctl daemon-reload $ sudo systemctl start jupyterhub We can see if JupyterHub is running with: $ sudo systemctl status jupyterhub Loaded: loaded (/etc/systemd/system/jupyterhub.service; Active: active (running)","title":"Run JupyterHub as a system service"},{"location":"systemd/#test-local-oauth","text":"Now we can point a web browser at our domain name and log into JupyterHub as our non-root user peter and the password we set for peter on the server. This time we are running with SSL security in place and even if we browse to http://mydomain.com , Nginx will forward us to https://mydomain.com . The JupyterHub login screen looks something like the screen capture below: A couple times I thought that JupyterHub was running after using systemctl start jupyterhub , but the JupyterHub wasn't working when I went to the server's web address. It turned out that JupyterHub wasn't running when I keyed in systemctl status jupyterhub . Most times looking for an error and tracking down the the error worked, but one time it seemed to be a problem with the http-configurable-proxy. The following command will shut down the proxy if you get stuck like I did (insert the number corresponding to the configurable-http-proxy process after the kill command): $ ps aux | grep configurable-http-proxy $ kill ####","title":"Test local OAuth"},{"location":"systemd/#summary","text":"In this section, we got JupyterHub running as a system service. We created a jupyterhub.service file in the /etc/systemd/system/ directory and made sure to include the PATH to our (jupyterhub) virtual environment and the path to our jupyterhub_config.py file. Finally, we reloaded the system service daemon and started the JupyterHub service. Then be opened a web browser and keyed in our domain name and logged into JupyterHub.","title":"Summary"},{"location":"systemd/#next-steps","text":"The next step is to add users to our server and see if we can log in as a different user than our non-root sudo user, peter .","title":"Next Steps"},{"location":"useful_commands/","text":"Useful Commands Below are some useful commands for setting up and running JupyterHub. kill configurable-http-proxy ps aux | grep configurable-http-proxy kill #### nginx sudo service nginx stop sudo service nginx start sudo service nginx restart nginx -t Shutdown and restart server sudo shutdown -r now Start JupyterHub with sudo (need to do this to allow other users to logon) sudo /home/peter/anaconda3/bin/jupyterhub Start jupyterhub as service, will run continuously sudo systemctl start jupyterhub sudo systemctl <start|stop|status> jupyterhub Add environmental variables: $ export OAUTH_CLIENT_SECRET=xxxxxxxxxxx Get the time and date from the command line $ date \"+%H:%M:%S %Y-%m-%d\" 17:36:58 2019-02-13 Gitpuller extension URLs https://domain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab change the systemctl start jupyterhub configurations If changes are made to /etc/systemd/system/jupyterhub.service needs to reload: sudo systemctl daemon-reload sudo systemctl start jupyterhub","title":"Useful Commands"},{"location":"useful_commands/#useful-commands","text":"Below are some useful commands for setting up and running JupyterHub.","title":"Useful Commands"},{"location":"useful_commands/#kill-configurable-http-proxy","text":"ps aux | grep configurable-http-proxy kill ####","title":"kill configurable-http-proxy"},{"location":"useful_commands/#nginx","text":"sudo service nginx stop sudo service nginx start sudo service nginx restart nginx -t","title":"nginx"},{"location":"useful_commands/#shutdown-and-restart-server","text":"sudo shutdown -r now","title":"Shutdown and restart server"},{"location":"useful_commands/#start-jupyterhub-with-sudo-need-to-do-this-to-allow-other-users-to-logon","text":"sudo /home/peter/anaconda3/bin/jupyterhub","title":"Start JupyterHub with sudo (need to do this to allow other users to logon)"},{"location":"useful_commands/#start-jupyterhub-as-service-will-run-continuously","text":"sudo systemctl start jupyterhub sudo systemctl <start|stop|status> jupyterhub","title":"Start jupyterhub as service, will run continuously"},{"location":"useful_commands/#add-environmental-variables","text":"$ export OAUTH_CLIENT_SECRET=xxxxxxxxxxx","title":"Add environmental variables:"},{"location":"useful_commands/#get-the-time-and-date-from-the-command-line","text":"$ date \"+%H:%M:%S %Y-%m-%d\" 17:36:58 2019-02-13","title":"Get the time and date from the command line"},{"location":"useful_commands/#gitpuller-extension-urls","text":"https://domain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"Gitpuller extension URLs"},{"location":"useful_commands/#change-the-systemctl-start-jupyterhub-configurations","text":"If changes are made to /etc/systemd/system/jupyterhub.service needs to reload: sudo systemctl daemon-reload sudo systemctl start jupyterhub","title":"change the systemctl start jupyterhub configurations"},{"location":"what_is_jupyterhub/","text":"What is JupyterHub? JupyterHub is a server-hosted distributed Jupyter notebook environment. JupyterHub allows users to log into a server and write Python code within a web browswer without any software installation on their local computer. Anywhere you have an internet connection, you can bring up a JupyterHub webpage and write/run Python code in a Jupyter notebook. The Jupyter notebook and JupyterLab interfaces that JupyterHub provides is the same Jupyter interface you run locally. Because JupyterHub runs in a web browser, it even works on tablets and phones. Below is an image of a running JupyterHub server. The JupyterLab interface is shown. Why JupyterHub? Why Jupyter Hub ? I am teaching an introductory engineering course this winter. In previous quarters, our college has taught MATLAB for three of the labs in this course. But this winter, my section is teaching Python and will cover the same concepts and learning outcomes. If we use Python in the class this winter, I would like to spend the class time coding and solving problems. I don't want to spend time during class downloading Python, creating virtual environments, troubleshooting installs, dealing with system vs. non-system versions of Python, installing packages, dealing with folder structure, explaining the difference between conda and pip, teaching command-line commands, going over Python on Windows compared to Python on MacOSX... The solution is to use JupyterHub. Summary JupyterHub is a way to run Jupyter notebooks on a remote server. Students can log on to a JupyterHub server then write and run Python code without installing any software. Students see the same interface on JupyterHub as they see running Jupyter notebooks locally. Next Steps Next, we'll review the tools used on our local computer to deploy JupterHub. These tools include PuTTY and FileZilla. We'll also review the standard locations for JupyterHub configuration and runtime files.","title":"What is JupyterHub?"},{"location":"what_is_jupyterhub/#what-is-jupyterhub","text":"JupyterHub is a server-hosted distributed Jupyter notebook environment. JupyterHub allows users to log into a server and write Python code within a web browswer without any software installation on their local computer. Anywhere you have an internet connection, you can bring up a JupyterHub webpage and write/run Python code in a Jupyter notebook. The Jupyter notebook and JupyterLab interfaces that JupyterHub provides is the same Jupyter interface you run locally. Because JupyterHub runs in a web browser, it even works on tablets and phones. Below is an image of a running JupyterHub server. The JupyterLab interface is shown.","title":"What is JupyterHub?"},{"location":"what_is_jupyterhub/#why-jupyterhub","text":"Why Jupyter Hub ? I am teaching an introductory engineering course this winter. In previous quarters, our college has taught MATLAB for three of the labs in this course. But this winter, my section is teaching Python and will cover the same concepts and learning outcomes. If we use Python in the class this winter, I would like to spend the class time coding and solving problems. I don't want to spend time during class downloading Python, creating virtual environments, troubleshooting installs, dealing with system vs. non-system versions of Python, installing packages, dealing with folder structure, explaining the difference between conda and pip, teaching command-line commands, going over Python on Windows compared to Python on MacOSX... The solution is to use JupyterHub.","title":"Why JupyterHub?"},{"location":"what_is_jupyterhub/#summary","text":"JupyterHub is a way to run Jupyter notebooks on a remote server. Students can log on to a JupyterHub server then write and run Python code without installing any software. Students see the same interface on JupyterHub as they see running Jupyter notebooks locally.","title":"Summary"},{"location":"what_is_jupyterhub/#next-steps","text":"Next, we'll review the tools used on our local computer to deploy JupterHub. These tools include PuTTY and FileZilla. We'll also review the standard locations for JupyterHub configuration and runtime files.","title":"Next Steps"}]}